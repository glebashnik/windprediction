_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 124)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               32000     
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 128)               32896     
_________________________________________________________________
batch_normalization_2 (Batch (None, 128)               512       
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 64)                8256      
_________________________________________________________________
dropout_1 (Dropout)          (None, 64)                0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 64)                256       
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 64)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 32)                2080      
_________________________________________________________________
batch_normalization_4 (Batch (None, 32)                128       
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         
_________________________________________________________________
dense_5 (Dense)              (None, 16)                528       
_________________________________________________________________
dropout_2 (Dropout)          (None, 16)                0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 16)                64        
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 16)                0         
_________________________________________________________________
dense_6 (Dense)              (None, 8)                 136       
_________________________________________________________________
batch_normalization_6 (Batch (None, 8)                 32        
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 8)                 0         
_________________________________________________________________
dense_7 (Dense)              (None, 2)                 18        
_________________________________________________________________
batch_normalization_7 (Batch (None, 2)                 8         
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 2)                 0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 3         
=================================================================
Total params: 77,941
Trainable params: 76,929
Non-trainable params: 1,012
_________________________________________________________________


Bessaker large
Training simple network with new dataset and dropout
Features: 124
Optimizer: adam
Dropoutrate: 0
Trained 2500 epochs
mean_absolute_error test evaluation
[4.519519622710281, 4.519519622710281]
mean_absolute_error training loss
2.6354039128879867
