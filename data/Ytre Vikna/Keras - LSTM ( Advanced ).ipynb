{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - LSTM (advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importere biblioteker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Making plots look better (Jupyter Notebook spesific)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['patch.force_edgecolor'] = True\n",
    "\n",
    "# Built in jupyter notebook commands\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importere datasett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 5237 entries, 1.745666504 to 2.072566406\n",
      "Data columns (total 65 columns):\n",
      "RRS.S2502.Gunit.M1 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G2-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M2 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G3-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M3 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G4-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M4 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G5-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M5 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G6-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M6 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G7-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M7 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G8-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M8 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G9-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M9 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1-G10-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M10 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G11-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M11 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G12-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M12 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G13-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M13 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G14-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M14 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G15-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M15 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G16-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M16 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G17-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M17 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-Sum-produksjon       5222 non-null float64\n",
      "DNMI_75410...........T0015A3-0120    5237 non-null float64\n",
      "/arome_windvel_6481_1056             5190 non-null float64\n",
      "DNMI_75220...........T0015A3-0120    5237 non-null float64\n",
      "/arome_windvel_6482_1114             5190 non-null float64\n",
      "DNMI_75550...........T0015A3-0120    5237 non-null float64\n",
      "/arome_windvel_6520_1098             5190 non-null float64\n",
      "STORM-YVik1-Vindhast-25km            5237 non-null float64\n",
      "STORM-YVik1-Vindretn-25km            5237 non-null int64\n",
      "/arome_windvel_6491_1087             5190 non-null float64\n",
      "/arome_airtemp_6491_1087             5190 non-null float64\n",
      "/arome_airtemp_6495_1081             5190 non-null float64\n",
      "/arome_airpress_6495_1081            5190 non-null float64\n",
      "/arome_winddir_6495_1081             5185 non-null float64\n",
      "/arome_windvel_6495_1081             5190 non-null float64\n",
      "/arome_airtemp_6495_1096             5190 non-null float64\n",
      "/arome_airpress_6495_1096            5190 non-null float64\n",
      "/arome_winddir_6495_1096             5185 non-null float64\n",
      "/arome_windvel_6495_1096             5190 non-null float64\n",
      "/arome_airtemp_6491_1087.1           5190 non-null float64\n",
      "/arome_airpress_6491_1087            5190 non-null float64\n",
      "/arome_winddir_6491_1087             5185 non-null float64\n",
      "/arome_windvel_6491_1087.1           5190 non-null float64\n",
      "/arome_airtemp_6486_1082             5190 non-null float64\n",
      "/arome_airpress_6486_1082            5190 non-null float64\n",
      "/arome_winddir_6486_1082             5185 non-null float64\n",
      "/arome_windvel_6486_1082             5190 non-null float64\n",
      "/arome_airtemp_6486_1093             5190 non-null float64\n",
      "/arome_airpress_6486_1093            5190 non-null float64\n",
      "/arome_winddir_6486_1093             5185 non-null float64\n",
      "/arome_windvel_6486_1093             5190 non-null float64\n",
      "Target                               5222 non-null float64\n",
      "dtypes: float64(47), int64(18)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "data_raw = pd.read_csv('data_ytrevikna_advanced.csv',sep =';', low_memory = False, index_col=0)\n",
    "\n",
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 5160 entries, 1.691883301 to 2.072566406\n",
      "Data columns (total 65 columns):\n",
      "RRS.S2502.Gunit.M1 G1.AVL            5160 non-null int64\n",
      "YVIK-YtreVikna1.-G2-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M2 G1.AVL            5160 non-null int64\n",
      "YVIK-YtreVikna1.-G3-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M3 G1.AVL            5160 non-null int64\n",
      "YVIK-YtreVikna1.-G4-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M4 G1.AVL            5160 non-null int64\n",
      "YVIK-YtreVikna1.-G5-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M5 G1.AVL            5160 non-null int64\n",
      "YVIK-YtreVikna1.-G6-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M6 G1.AVL            5160 non-null int64\n",
      "YVIK-YtreVikna1.-G7-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M7 G1.AVL            5160 non-null int64\n",
      "YVIK-YtreVikna1.-G8-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M8 G1.AVL            5160 non-null int64\n",
      "YVIK-YtreVikna1.-G9-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M9 G1.AVL            5160 non-null int64\n",
      "YVIK-YtreVikna1-G10-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M10 G1.AVL           5160 non-null int64\n",
      "YVIK-YtreVikna1-G11-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M11 G1.AVL           5160 non-null int64\n",
      "YVIK-YtreVikna1-G12-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M12 G1.AVL           5160 non-null int64\n",
      "YVIK-YtreVikna1-G13-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M13 G1.AVL           5160 non-null int64\n",
      "YVIK-YtreVikna1-G14-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M14 G1.AVL           5160 non-null int64\n",
      "YVIK-YtreVikna1-G15-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M15 G1.AVL           5160 non-null int64\n",
      "YVIK-YtreVikna1-G16-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M16 G1.AVL           5160 non-null int64\n",
      "YVIK-YtreVikna1-G17-T4015A3 -0104    5160 non-null float64\n",
      "RRS.S2502.Gunit.M17 G1.AVL           5160 non-null int64\n",
      "YVIK-YtreVikna1-Sum-produksjon       5160 non-null float64\n",
      "DNMI_75410...........T0015A3-0120    5160 non-null float64\n",
      "/arome_windvel_6481_1056             5160 non-null float64\n",
      "DNMI_75220...........T0015A3-0120    5160 non-null float64\n",
      "/arome_windvel_6482_1114             5160 non-null float64\n",
      "DNMI_75550...........T0015A3-0120    5160 non-null float64\n",
      "/arome_windvel_6520_1098             5160 non-null float64\n",
      "STORM-YVik1-Vindhast-25km            5160 non-null float64\n",
      "STORM-YVik1-Vindretn-25km            5160 non-null int64\n",
      "/arome_windvel_6491_1087             5160 non-null float64\n",
      "/arome_airtemp_6491_1087             5160 non-null float64\n",
      "/arome_airtemp_6495_1081             5160 non-null float64\n",
      "/arome_airpress_6495_1081            5160 non-null float64\n",
      "/arome_winddir_6495_1081             5160 non-null float64\n",
      "/arome_windvel_6495_1081             5160 non-null float64\n",
      "/arome_airtemp_6495_1096             5160 non-null float64\n",
      "/arome_airpress_6495_1096            5160 non-null float64\n",
      "/arome_winddir_6495_1096             5160 non-null float64\n",
      "/arome_windvel_6495_1096             5160 non-null float64\n",
      "/arome_airtemp_6491_1087.1           5160 non-null float64\n",
      "/arome_airpress_6491_1087            5160 non-null float64\n",
      "/arome_winddir_6491_1087             5160 non-null float64\n",
      "/arome_windvel_6491_1087.1           5160 non-null float64\n",
      "/arome_airtemp_6486_1082             5160 non-null float64\n",
      "/arome_airpress_6486_1082            5160 non-null float64\n",
      "/arome_winddir_6486_1082             5160 non-null float64\n",
      "/arome_windvel_6486_1082             5160 non-null float64\n",
      "/arome_airtemp_6486_1093             5160 non-null float64\n",
      "/arome_airpress_6486_1093            5160 non-null float64\n",
      "/arome_winddir_6486_1093             5160 non-null float64\n",
      "/arome_windvel_6486_1093             5160 non-null float64\n",
      "Target                               5160 non-null float64\n",
      "dtypes: float64(47), int64(18)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "data = data_raw.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "num_features = len(data.columns) -1\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konvertere til numpy-arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konverterer pandas.DataFrame til en numpy array\n",
    "all_features_and_target_value = data.values.astype(\"float32\")\n",
    "\n",
    "# Trekker ut alle features (5 aromepunkter med 4 features + delayed = 21 features)\n",
    "x = all_features_and_target_value[:,0:num_features]\n",
    "\n",
    "# Trekker ut produksjonen som y-verdi\n",
    "y = all_features_and_target_value[:,num_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skalere data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Lage en scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Anvende på features, her lagret i variablen x.\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state = 67, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konvertere til tidserie matrise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definere variabler:\n",
    "n_backward = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for making time series\n",
    "def make_time_series(row_features, look_back_num):\n",
    "    list_of_matrices = []\n",
    "    \n",
    "    num_time_steps = look_back_num + 1\n",
    "    \n",
    "    i = num_time_steps\n",
    "    \n",
    "    while i < len(row_features):\n",
    "        list_of_matrices.append(row_features[(i-num_time_steps):i,:])\n",
    "        \n",
    "        i = i + 1\n",
    "    \n",
    "    return list_of_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_matrix = np.asarray(make_time_series(X_train, n_backward))\n",
    "x_test_matrix = np.asarray(make_time_series(X_test, n_backward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3608, 4, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_matrix[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.01747815,  0.        ,  0.77792865,  1.        ,\n",
       "         0.86680442,  1.        ,  0.87214816,  1.        ,  0.86295372,\n",
       "         1.        ,  0.94334579,  1.        ,  0.93343031,  1.        ,\n",
       "         0.        ,  1.        ,  0.92894208,  1.        ,  0.68720323,\n",
       "         1.        ,  0.73323661,  1.        ,  0.37420234,  1.        ,\n",
       "         0.63871813,  1.        ,  0.84074271,  1.        ,  0.90905797,\n",
       "         1.        ,  0.7998963 ,  1.        ,  0.73661494,  0.34328359,\n",
       "         0.3069464 ,  0.26829267,  0.19148017,  0.36723161,  0.32739758,\n",
       "         0.47422677,  0.93036211,  0.23920847,  0.49230886,  0.50394714,\n",
       "         0.62438965,  0.95576745,  0.22623329,  0.49417847,  0.61640549,\n",
       "         0.95209366,  0.26585844,  0.49230886,  0.56917381,  0.95821154,\n",
       "         0.23920847,  0.4806087 ,  0.58900356,  0.9543305 ,  0.22280048,\n",
       "         0.4798933 ,  0.59886265,  0.95918965,  0.18142872],\n",
       "       [ 1.        ,  0.01747815,  0.        ,  0.85387242,  1.        ,\n",
       "         0.88434619,  1.        ,  0.83569247,  1.        ,  0.86643803,\n",
       "         1.        ,  0.92169714,  1.        ,  0.92736834,  1.        ,\n",
       "         0.        ,  1.        ,  0.87881094,  1.        ,  0.72655976,\n",
       "         1.        ,  0.74390101,  1.        ,  0.42947799,  1.        ,\n",
       "         0.58397698,  1.        ,  0.77533662,  1.        ,  0.796992  ,\n",
       "         1.        ,  0.78299475,  1.        ,  0.72783774,  0.32835823,\n",
       "         0.38272455,  0.27317071,  0.16851872,  0.36723161,  0.39317593,\n",
       "         0.45876282,  0.9247911 ,  0.22836772,  0.49561447,  0.51274586,\n",
       "         0.62963295,  0.93758851,  0.21046965,  0.50185001,  0.62150478,\n",
       "         0.9336763 ,  0.25524431,  0.49561447,  0.57434464,  0.93764186,\n",
       "         0.22836772,  0.49370295,  0.59403896,  0.93922883,  0.22857942,\n",
       "         0.48085028,  0.60430336,  0.94105911,  0.18054129],\n",
       "       [ 1.        ,  0.01747815,  0.        ,  0.83423179,  1.        ,\n",
       "         0.82803506,  1.        ,  0.85346919,  1.        ,  0.83983099,\n",
       "         1.        ,  0.92458367,  1.        ,  0.92667484,  1.        ,\n",
       "         0.        ,  1.        ,  0.84966856,  1.        ,  0.68835217,\n",
       "         1.        ,  0.72885746,  1.        ,  0.35333052,  1.        ,\n",
       "         0.61147565,  1.        ,  0.75276899,  1.        ,  0.82509029,\n",
       "         1.        ,  0.78581399,  1.        ,  0.71944487,  0.33134329,\n",
       "         0.38272455,  0.31219512,  0.16851872,  0.33050844,  0.39317593,\n",
       "         0.44329891,  0.92200553,  0.22354802,  0.51409107,  0.53007662,\n",
       "         0.63272858,  0.92861468,  0.20685732,  0.51141906,  0.62459564,\n",
       "         0.91957635,  0.24968852,  0.51409107,  0.57764339,  0.92462921,\n",
       "         0.22354802,  0.51219082,  0.59761238,  0.92527175,  0.22363193,\n",
       "         0.50129294,  0.60753155,  0.92623854,  0.17667928],\n",
       "       [ 1.        ,  0.01747815,  0.        ,  0.5135116 ,  1.        ,\n",
       "         0.61508203,  1.        ,  0.53654587,  1.        ,  0.58524519,\n",
       "         1.        ,  0.69269353,  1.        ,  0.64595628,  1.        ,\n",
       "         0.        ,  1.        ,  0.56476104,  1.        ,  0.43443111,\n",
       "         1.        ,  0.53407228,  1.        ,  0.24722923,  1.        ,\n",
       "         0.43141603,  1.        ,  0.50628036,  1.        ,  0.52837288,\n",
       "         1.        ,  0.45160308,  1.        ,  0.48532018,  0.26865673,\n",
       "         0.34711322,  0.31707317,  0.17310083,  0.26271182,  0.37320647,\n",
       "         0.42783505,  0.91643453,  0.21813434,  0.50444728,  0.5280388 ,\n",
       "         0.64080906,  0.91955471,  0.20199449,  0.51472598,  0.63266754,\n",
       "         0.91548347,  0.24101301,  0.50444728,  0.58564949,  0.91937077,\n",
       "         0.21813434,  0.49706468,  0.60562229,  0.91785747,  0.21770859,\n",
       "         0.49472153,  0.61560059,  0.92276406,  0.17185271]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27.92919922,  18.84036446,  16.92293167, ...,   2.20245004,\n",
       "         2.47471666,   2.31861663], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fjerne 'n_backward' antall rader, for å få like store sett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_matrix = np.delete(y_train, [x for x in range(n_backward+1)], 0)\n",
    "y_test_matrix = np.delete(y_test, [x for x in range(n_backward+1)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3608,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importere modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_keras_model = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sette opp layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input layer\n",
    "dnn_keras_model.add(layers.LSTM(units=32, return_sequences = True, input_shape=(x_train_matrix.shape[1],x_train_matrix.shape[2]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Hidden Layers'''\n",
    "#dnn_keras_model.add(layers.LSTM(units=32, return_sequences = True))\n",
    "\n",
    "dnn_keras_model.add(layers.LSTM(units=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "dnn_keras_model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kompilere modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import losses,optimizers,metrics,activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Kompilere - Alternative lossfunctions: mean_squared_error\n",
    "dnn_keras_model.compile(optimizer='adam', loss = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trene modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import losses,optimizers,metrics,activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks og checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=500)\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint('checkpoint_model_LSTM_advanced.h5', monitor = 'val_loss', \n",
    "                                       verbose = 1, save_best_only= True, mode= 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2886 samples, validate on 722 samples\n",
      "Epoch 1/1000\n",
      "Epoch 00000: val_loss improved from inf to 10.98663, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "2s - loss: 11.2825 - val_loss: 10.9866\n",
      "Epoch 2/1000\n",
      "Epoch 00001: val_loss improved from 10.98663 to 10.10072, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0451 - val_loss: 10.1007\n",
      "Epoch 3/1000\n",
      "Epoch 00002: val_loss improved from 10.10072 to 9.22760, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 9.0874 - val_loss: 9.2276\n",
      "Epoch 4/1000\n",
      "Epoch 00003: val_loss improved from 9.22760 to 8.56588, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 8.4220 - val_loss: 8.5659\n",
      "Epoch 5/1000\n",
      "Epoch 00004: val_loss improved from 8.56588 to 7.91994, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 7.7991 - val_loss: 7.9199\n",
      "Epoch 6/1000\n",
      "Epoch 00005: val_loss improved from 7.91994 to 7.42158, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 7.3204 - val_loss: 7.4216\n",
      "Epoch 7/1000\n",
      "Epoch 00006: val_loss improved from 7.42158 to 6.96881, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 6.9087 - val_loss: 6.9688\n",
      "Epoch 8/1000\n",
      "Epoch 00007: val_loss improved from 6.96881 to 6.58345, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 6.5392 - val_loss: 6.5835\n",
      "Epoch 9/1000\n",
      "Epoch 00008: val_loss improved from 6.58345 to 6.29673, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 6.2433 - val_loss: 6.2967\n",
      "Epoch 10/1000\n",
      "Epoch 00009: val_loss improved from 6.29673 to 5.99877, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 5.9545 - val_loss: 5.9988\n",
      "Epoch 11/1000\n",
      "Epoch 00010: val_loss improved from 5.99877 to 5.74569, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 5.7237 - val_loss: 5.7457\n",
      "Epoch 12/1000\n",
      "Epoch 00011: val_loss improved from 5.74569 to 5.53079, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 5.4610 - val_loss: 5.5308\n",
      "Epoch 13/1000\n",
      "Epoch 00012: val_loss improved from 5.53079 to 5.24140, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 5.2431 - val_loss: 5.2414\n",
      "Epoch 14/1000\n",
      "Epoch 00013: val_loss improved from 5.24140 to 5.08971, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 4.9989 - val_loss: 5.0897\n",
      "Epoch 15/1000\n",
      "Epoch 00014: val_loss improved from 5.08971 to 4.85809, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 4.7608 - val_loss: 4.8581\n",
      "Epoch 16/1000\n",
      "Epoch 00015: val_loss improved from 4.85809 to 4.71091, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 4.5687 - val_loss: 4.7109\n",
      "Epoch 17/1000\n",
      "Epoch 00016: val_loss improved from 4.71091 to 4.54141, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 4.3920 - val_loss: 4.5414\n",
      "Epoch 18/1000\n",
      "Epoch 00017: val_loss improved from 4.54141 to 4.32491, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 4.1817 - val_loss: 4.3249\n",
      "Epoch 19/1000\n",
      "Epoch 00018: val_loss improved from 4.32491 to 4.28878, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 4.0438 - val_loss: 4.2888\n",
      "Epoch 20/1000\n",
      "Epoch 00019: val_loss improved from 4.28878 to 4.17329, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 3.8662 - val_loss: 4.1733\n",
      "Epoch 21/1000\n",
      "Epoch 00020: val_loss improved from 4.17329 to 3.88551, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 3.6994 - val_loss: 3.8855\n",
      "Epoch 22/1000\n",
      "Epoch 00021: val_loss improved from 3.88551 to 3.75967, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 3.5227 - val_loss: 3.7597\n",
      "Epoch 23/1000\n",
      "Epoch 00022: val_loss improved from 3.75967 to 3.64547, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 3.4142 - val_loss: 3.6455\n",
      "Epoch 24/1000\n",
      "Epoch 00023: val_loss improved from 3.64547 to 3.57981, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 3.3035 - val_loss: 3.5798\n",
      "Epoch 25/1000\n",
      "Epoch 00024: val_loss improved from 3.57981 to 3.55419, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 3.1727 - val_loss: 3.5542\n",
      "Epoch 26/1000\n",
      "Epoch 00025: val_loss improved from 3.55419 to 3.37353, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 3.0527 - val_loss: 3.3735\n",
      "Epoch 27/1000\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 2.9663 - val_loss: 3.4006\n",
      "Epoch 28/1000\n",
      "Epoch 00027: val_loss improved from 3.37353 to 3.29333, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 2.9254 - val_loss: 3.2933\n",
      "Epoch 29/1000\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 2.9001 - val_loss: 3.3425\n",
      "Epoch 30/1000\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 2.7848 - val_loss: 3.2977\n",
      "Epoch 31/1000\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 2.7807 - val_loss: 3.6256\n",
      "Epoch 32/1000\n",
      "Epoch 00031: val_loss improved from 3.29333 to 3.25124, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 2.7114 - val_loss: 3.2512\n",
      "Epoch 33/1000\n",
      "Epoch 00032: val_loss improved from 3.25124 to 3.21505, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 2.6910 - val_loss: 3.2150\n",
      "Epoch 34/1000\n",
      "Epoch 00033: val_loss improved from 3.21505 to 3.17088, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 2.6818 - val_loss: 3.1709\n",
      "Epoch 35/1000\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 2.6494 - val_loss: 3.3087\n",
      "Epoch 36/1000\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 2.5908 - val_loss: 3.6740\n",
      "Epoch 37/1000\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 2.6619 - val_loss: 3.2122\n",
      "Epoch 38/1000\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 2.5543 - val_loss: 3.3817\n",
      "Epoch 39/1000\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 2.5484 - val_loss: 3.5753\n",
      "Epoch 40/1000\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 2.5996 - val_loss: 3.2431\n",
      "Epoch 41/1000\n",
      "Epoch 00040: val_loss improved from 3.17088 to 3.15784, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 2.6207 - val_loss: 3.1578\n",
      "Epoch 42/1000\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 2.4851 - val_loss: 3.2091\n",
      "Epoch 43/1000\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 2.5219 - val_loss: 3.4205\n",
      "Epoch 44/1000\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 2.5335 - val_loss: 3.2191\n",
      "Epoch 45/1000\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 2.4570 - val_loss: 3.5572\n",
      "Epoch 46/1000\n",
      "Epoch 00045: val_loss improved from 3.15784 to 3.13825, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 2.4324 - val_loss: 3.1382\n",
      "Epoch 47/1000\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 2.4003 - val_loss: 3.4583\n",
      "Epoch 48/1000\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 2.4123 - val_loss: 3.2606\n",
      "Epoch 49/1000\n",
      "Epoch 00048: val_loss improved from 3.13825 to 3.01413, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 2.3875 - val_loss: 3.0141\n",
      "Epoch 50/1000\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 2.4521 - val_loss: 3.2813\n",
      "Epoch 51/1000\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 2.4281 - val_loss: 3.0555\n",
      "Epoch 52/1000\n",
      "Epoch 00051: val_loss did not improve\n",
      "0s - loss: 2.3488 - val_loss: 3.1403\n",
      "Epoch 53/1000\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 2.3365 - val_loss: 3.4137\n",
      "Epoch 54/1000\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 2.3193 - val_loss: 3.1712\n",
      "Epoch 55/1000\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 2.3826 - val_loss: 3.3938\n",
      "Epoch 56/1000\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 2.3077 - val_loss: 3.0948\n",
      "Epoch 57/1000\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 2.2901 - val_loss: 3.3294\n",
      "Epoch 58/1000\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 2.3792 - val_loss: 3.5564\n",
      "Epoch 59/1000\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 2.2993 - val_loss: 3.2334\n",
      "Epoch 60/1000\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 2.2723 - val_loss: 3.0929\n",
      "Epoch 61/1000\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 2.2460 - val_loss: 3.3161\n",
      "Epoch 62/1000\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 2.3267 - val_loss: 3.2471\n",
      "Epoch 63/1000\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 2.2640 - val_loss: 3.1735\n",
      "Epoch 64/1000\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 2.3172 - val_loss: 3.1330\n",
      "Epoch 65/1000\n",
      "Epoch 00064: val_loss improved from 3.01413 to 2.96667, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 2.2778 - val_loss: 2.9667\n",
      "Epoch 66/1000\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 2.3082 - val_loss: 3.0432\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 2.2344 - val_loss: 3.1381\n",
      "Epoch 68/1000\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 2.2615 - val_loss: 3.3553\n",
      "Epoch 69/1000\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 2.1662 - val_loss: 3.0950\n",
      "Epoch 70/1000\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 2.1820 - val_loss: 3.1745\n",
      "Epoch 71/1000\n",
      "Epoch 00070: val_loss did not improve\n",
      "0s - loss: 2.2078 - val_loss: 3.1395\n",
      "Epoch 72/1000\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 2.1953 - val_loss: 2.9782\n",
      "Epoch 73/1000\n",
      "Epoch 00072: val_loss improved from 2.96667 to 2.92440, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 2.2060 - val_loss: 2.9244\n",
      "Epoch 74/1000\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 2.1533 - val_loss: 3.2373\n",
      "Epoch 75/1000\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 2.1428 - val_loss: 3.3704\n",
      "Epoch 76/1000\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 2.1686 - val_loss: 3.4456\n",
      "Epoch 77/1000\n",
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 2.1562 - val_loss: 2.9379\n",
      "Epoch 78/1000\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 2.1643 - val_loss: 3.0798\n",
      "Epoch 79/1000\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 2.1209 - val_loss: 3.0764\n",
      "Epoch 80/1000\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 2.0934 - val_loss: 3.3396\n",
      "Epoch 81/1000\n",
      "Epoch 00080: val_loss did not improve\n",
      "0s - loss: 2.0932 - val_loss: 3.2523\n",
      "Epoch 82/1000\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 2.1296 - val_loss: 3.1156\n",
      "Epoch 83/1000\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 2.1040 - val_loss: 3.4720\n",
      "Epoch 84/1000\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 2.1900 - val_loss: 3.4576\n",
      "Epoch 85/1000\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 2.0956 - val_loss: 3.3324\n",
      "Epoch 86/1000\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 2.1991 - val_loss: 3.1026\n",
      "Epoch 87/1000\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 2.0732 - val_loss: 3.0952\n",
      "Epoch 88/1000\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 2.0657 - val_loss: 3.1482\n",
      "Epoch 89/1000\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 2.0361 - val_loss: 3.6479\n",
      "Epoch 90/1000\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 2.0433 - val_loss: 3.2343\n",
      "Epoch 91/1000\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 2.0416 - val_loss: 3.1180\n",
      "Epoch 92/1000\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 2.1378 - val_loss: 3.1168\n",
      "Epoch 93/1000\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 2.0820 - val_loss: 3.0165\n",
      "Epoch 94/1000\n",
      "Epoch 00093: val_loss did not improve\n",
      "0s - loss: 2.0454 - val_loss: 3.2965\n",
      "Epoch 95/1000\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 2.0592 - val_loss: 3.2969\n",
      "Epoch 96/1000\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 2.0434 - val_loss: 3.2336\n",
      "Epoch 97/1000\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 1.9835 - val_loss: 3.1978\n",
      "Epoch 98/1000\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 2.0913 - val_loss: 3.5287\n",
      "Epoch 99/1000\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 1.9718 - val_loss: 3.2808\n",
      "Epoch 100/1000\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 2.0036 - val_loss: 3.1746\n",
      "Epoch 101/1000\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 2.0662 - val_loss: 3.3035\n",
      "Epoch 102/1000\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 2.0020 - val_loss: 3.1501\n",
      "Epoch 103/1000\n",
      "Epoch 00102: val_loss did not improve\n",
      "0s - loss: 1.9452 - val_loss: 3.3343\n",
      "Epoch 104/1000\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 1.9568 - val_loss: 3.1249\n",
      "Epoch 105/1000\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 2.0004 - val_loss: 3.7332\n",
      "Epoch 106/1000\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 1.9723 - val_loss: 2.9496\n",
      "Epoch 107/1000\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 1.9333 - val_loss: 3.3421\n",
      "Epoch 108/1000\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 1.9746 - val_loss: 3.0251\n",
      "Epoch 109/1000\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 1.9035 - val_loss: 3.2096\n",
      "Epoch 110/1000\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 1.9537 - val_loss: 3.6564\n",
      "Epoch 111/1000\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 1.9259 - val_loss: 3.3070\n",
      "Epoch 112/1000\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 1.9155 - val_loss: 3.2874\n",
      "Epoch 113/1000\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 1.8970 - val_loss: 3.7100\n",
      "Epoch 114/1000\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 1.9433 - val_loss: 3.2820\n",
      "Epoch 115/1000\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 1.9137 - val_loss: 3.4308\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-4f1bfc4c8923>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m dnn_keras_model.fit(x_train_matrix,y_train_matrix, epochs = 1000, batch_size=32, verbose=2, \n\u001b[0;32m      4\u001b[0m                        \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                        callbacks=[checkpoint,early_stopping])\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m         \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1442\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1077\u001b[0m         \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2411\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2413\u001b[1;33m         **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2414\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Trene modellen\n",
    "np.random.seed(7)\n",
    "dnn_keras_model.fit(x_train_matrix,y_train_matrix, epochs = 1000, batch_size=32, verbose=2, \n",
    "                       validation_split=0.2,\n",
    "                       callbacks=[checkpoint,early_stopping])\n",
    "\n",
    "\n",
    "# validation_split=0.20\n",
    "#validation_data=(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finished_model = dnn_keras_model\n",
    "\n",
    "finished_model = models.load_model('checkpoint_model_LSTM_advanced.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediksjon på testsett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = finished_model.predict(x_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5000 epocs , b_size = 10, 24(24)[10](1)\n",
    "print('Mean Absolute Error: \\t\\t\\t', metrics.mean_absolute_error(y_test_matrix, final_preds))\n",
    "print('Mean Squared Error: \\t\\t\\t', metrics.mean_squared_error(y_test_matrix, final_preds))\n",
    "print('Root Mean Squared Error: \\t\\t', np.sqrt(metrics.mean_squared_error(y_test_matrix, final_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediksjon på treningdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = finished_model.predict(x_train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 70% av data (benyttet til treningen)\n",
    "print('Mean Absolute Error: \\t\\t\\t', metrics.mean_absolute_error(y_train_matrix,train_preds))\n",
    "print('Mean Squared Error: \\t\\t\\t', metrics.mean_squared_error(y_train_matrix, train_preds))\n",
    "print('Root Mean Squared Error: \\t\\t', np.sqrt(metrics.mean_squared_error(y_train_matrix, train_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualisere resultater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Lager oversikt over testdataen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = list(final_preds)\n",
    "\n",
    "predictions_list = []\n",
    "\n",
    "for pred in predictions:\n",
    "    predictions_list.append(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Oversikt = pd.DataFrame(data = {'real': y_test_matrix, 'predicitions': predictions_list})\n",
    "\n",
    "Oversikt['differanse'] = Oversikt['real'] - Oversikt['predicitions'] \n",
    "\n",
    "Oversikt['abs_diff'] = Oversikt['differanse'].apply(abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot med fargekodede prediskjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = Oversikt.plot.scatter(x='real',y='predicitions',\n",
    "                   c='abs_diff',cmap='coolwarm', figsize = (20,10))\n",
    "\n",
    "ax.set_xlabel(\"x label\")\n",
    "\n",
    "#remove spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "#fig.savefig('keras_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feilfordelingen av prediksjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = Oversikt['differanse'].hist(bins=60,figsize = (20,10))\n",
    "\n",
    "plt.xlabel('Verdi av feilprediskjon')\n",
    "plt.ylabel('Antall timer')\n",
    "plt.title('Fordeling av feilprediskjoner')\n",
    "\n",
    "#remove spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "#fig.savefig('hist av abs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ekte plott av prediksjonene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forsøk på å hente ut et utdrag av dataen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_predictions = finished_model.predict(x[:,:])\n",
    "\n",
    "predictions_all = list(all_predictions)\n",
    "\n",
    "predictions_all_list = []\n",
    "\n",
    "for pred in predictions_all:\n",
    "    predictions_all_list.append(pred[0])\n",
    "    \n",
    "timeline = pd.DataFrame(data = {'real': y[:], 'predicitions': predictions_all_list})\n",
    "\n",
    "# Adjust in order to plot 'dagens modell'\n",
    "data_raw.dropna(inplace=True)\n",
    "data_raw.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidsplot av data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Justere tidslinjen på plottet\n",
    "start = 0\n",
    "slutt = 20\n",
    "\n",
    "ax = timeline.loc[start:slutt,'real'].plot(figsize=(20,8))\n",
    "ax = timeline.loc[start:slutt,'predicitions'].plot(figsize=(20,8))\n",
    "ax = data_raw.loc[start:slutt,'YVIK-YtreVikna1-Sum-produksjon'].plot(figsize=(20,8))\n",
    "\n",
    " \n",
    "plt.xlabel('Tid (antall timer)')\n",
    "plt.ylabel('Produksjon i Mega Watt (MW)')\n",
    "plt.title('Utdrag fra tidsperioden')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "\n",
    "#remove spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Saves figure\n",
    "fig = ax.get_figure()\n",
    "#fig.savefig('september10.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
