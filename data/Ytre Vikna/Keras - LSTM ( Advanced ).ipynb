{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importere biblioteker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Making plots look better (Jupyter Notebook spesific)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['patch.force_edgecolor'] = True\n",
    "\n",
    "# Built in jupyter notebook commands\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importere datasett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5237 entries, 0 to 5236\n",
      "Data columns (total 66 columns):\n",
      "YVIK-YtreVikna1.-G1-T4015A3 -0104    4954 non-null float64\n",
      "RRS.S2502.Gunit.M1 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G2-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M2 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G3-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M3 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G4-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M4 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G5-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M5 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G6-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M6 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G7-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M7 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G8-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M8 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1.-G9-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M9 G1.AVL            5237 non-null int64\n",
      "YVIK-YtreVikna1-G10-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M10 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G11-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M11 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G12-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M12 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G13-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M13 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G14-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M14 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G15-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M15 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G16-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M16 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-G17-T4015A3 -0104    5222 non-null float64\n",
      "RRS.S2502.Gunit.M17 G1.AVL           5237 non-null int64\n",
      "YVIK-YtreVikna1-Sum-produksjon       5222 non-null float64\n",
      "DNMI_75410...........T0015A3-0120    5237 non-null float64\n",
      "/arome_windvel_6481_1056             5190 non-null float64\n",
      "DNMI_75220...........T0015A3-0120    5237 non-null float64\n",
      "/arome_windvel_6482_1114             5190 non-null float64\n",
      "DNMI_75550...........T0015A3-0120    5237 non-null float64\n",
      "/arome_windvel_6520_1098             5190 non-null float64\n",
      "STORM-YVik1-Vindhast-25km            5237 non-null float64\n",
      "STORM-YVik1-Vindretn-25km            5237 non-null int64\n",
      "/arome_windvel_6491_1087             5190 non-null float64\n",
      "/arome_airtemp_6491_1087             5190 non-null float64\n",
      "/arome_airtemp_6495_1081             5190 non-null float64\n",
      "/arome_airpress_6495_1081            5190 non-null float64\n",
      "/arome_winddir_6495_1081             5185 non-null float64\n",
      "/arome_windvel_6495_1081             5190 non-null float64\n",
      "/arome_airtemp_6495_1096             5190 non-null float64\n",
      "/arome_airpress_6495_1096            5190 non-null float64\n",
      "/arome_winddir_6495_1096             5185 non-null float64\n",
      "/arome_windvel_6495_1096             5190 non-null float64\n",
      "/arome_airtemp_6491_1087.1           5190 non-null float64\n",
      "/arome_airpress_6491_1087            5190 non-null float64\n",
      "/arome_winddir_6491_1087             5185 non-null float64\n",
      "/arome_windvel_6491_1087.1           5190 non-null float64\n",
      "/arome_airtemp_6486_1082             5190 non-null float64\n",
      "/arome_airpress_6486_1082            5190 non-null float64\n",
      "/arome_winddir_6486_1082             5185 non-null float64\n",
      "/arome_windvel_6486_1082             5190 non-null float64\n",
      "/arome_airtemp_6486_1093             5190 non-null float64\n",
      "/arome_airpress_6486_1093            5190 non-null float64\n",
      "/arome_winddir_6486_1093             5185 non-null float64\n",
      "/arome_windvel_6486_1093             5190 non-null float64\n",
      "Target                               5222 non-null float64\n",
      "dtypes: float64(48), int64(18)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "data_raw = pd.read_csv('data_ytrevikna_advanced.csv',sep =';', low_memory = False)\n",
    "\n",
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4895 entries, 5 to 5236\n",
      "Data columns (total 66 columns):\n",
      "YVIK-YtreVikna1.-G1-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M1 G1.AVL            4895 non-null int64\n",
      "YVIK-YtreVikna1.-G2-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M2 G1.AVL            4895 non-null int64\n",
      "YVIK-YtreVikna1.-G3-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M3 G1.AVL            4895 non-null int64\n",
      "YVIK-YtreVikna1.-G4-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M4 G1.AVL            4895 non-null int64\n",
      "YVIK-YtreVikna1.-G5-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M5 G1.AVL            4895 non-null int64\n",
      "YVIK-YtreVikna1.-G6-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M6 G1.AVL            4895 non-null int64\n",
      "YVIK-YtreVikna1.-G7-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M7 G1.AVL            4895 non-null int64\n",
      "YVIK-YtreVikna1.-G8-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M8 G1.AVL            4895 non-null int64\n",
      "YVIK-YtreVikna1.-G9-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M9 G1.AVL            4895 non-null int64\n",
      "YVIK-YtreVikna1-G10-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M10 G1.AVL           4895 non-null int64\n",
      "YVIK-YtreVikna1-G11-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M11 G1.AVL           4895 non-null int64\n",
      "YVIK-YtreVikna1-G12-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M12 G1.AVL           4895 non-null int64\n",
      "YVIK-YtreVikna1-G13-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M13 G1.AVL           4895 non-null int64\n",
      "YVIK-YtreVikna1-G14-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M14 G1.AVL           4895 non-null int64\n",
      "YVIK-YtreVikna1-G15-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M15 G1.AVL           4895 non-null int64\n",
      "YVIK-YtreVikna1-G16-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M16 G1.AVL           4895 non-null int64\n",
      "YVIK-YtreVikna1-G17-T4015A3 -0104    4895 non-null float64\n",
      "RRS.S2502.Gunit.M17 G1.AVL           4895 non-null int64\n",
      "YVIK-YtreVikna1-Sum-produksjon       4895 non-null float64\n",
      "DNMI_75410...........T0015A3-0120    4895 non-null float64\n",
      "/arome_windvel_6481_1056             4895 non-null float64\n",
      "DNMI_75220...........T0015A3-0120    4895 non-null float64\n",
      "/arome_windvel_6482_1114             4895 non-null float64\n",
      "DNMI_75550...........T0015A3-0120    4895 non-null float64\n",
      "/arome_windvel_6520_1098             4895 non-null float64\n",
      "STORM-YVik1-Vindhast-25km            4895 non-null float64\n",
      "STORM-YVik1-Vindretn-25km            4895 non-null int64\n",
      "/arome_windvel_6491_1087             4895 non-null float64\n",
      "/arome_airtemp_6491_1087             4895 non-null float64\n",
      "/arome_airtemp_6495_1081             4895 non-null float64\n",
      "/arome_airpress_6495_1081            4895 non-null float64\n",
      "/arome_winddir_6495_1081             4895 non-null float64\n",
      "/arome_windvel_6495_1081             4895 non-null float64\n",
      "/arome_airtemp_6495_1096             4895 non-null float64\n",
      "/arome_airpress_6495_1096            4895 non-null float64\n",
      "/arome_winddir_6495_1096             4895 non-null float64\n",
      "/arome_windvel_6495_1096             4895 non-null float64\n",
      "/arome_airtemp_6491_1087.1           4895 non-null float64\n",
      "/arome_airpress_6491_1087            4895 non-null float64\n",
      "/arome_winddir_6491_1087             4895 non-null float64\n",
      "/arome_windvel_6491_1087.1           4895 non-null float64\n",
      "/arome_airtemp_6486_1082             4895 non-null float64\n",
      "/arome_airpress_6486_1082            4895 non-null float64\n",
      "/arome_winddir_6486_1082             4895 non-null float64\n",
      "/arome_windvel_6486_1082             4895 non-null float64\n",
      "/arome_airtemp_6486_1093             4895 non-null float64\n",
      "/arome_airpress_6486_1093            4895 non-null float64\n",
      "/arome_winddir_6486_1093             4895 non-null float64\n",
      "/arome_windvel_6486_1093             4895 non-null float64\n",
      "Target                               4895 non-null float64\n",
      "dtypes: float64(48), int64(18)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "data = data_raw.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "num_features = len(data.columns) -1\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konvertere til numpy-arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Konverterer pandas.DataFrame til en numpy array\n",
    "all_features_and_target_value = data.values.astype(\"float32\")\n",
    "\n",
    "# Trekker ut alle features (5 aromepunkter med 4 features + delayed = 21 features)\n",
    "x = all_features_and_target_value[:,0:num_features]\n",
    "\n",
    "# Trekker ut produksjonen som y-verdi\n",
    "y = all_features_and_target_value[:,num_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state = 67, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skalere data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Lage en scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Anvende på features, her lagret i variablen x.\n",
    "scaled_x_train = scaler.fit_transform(X_train)\n",
    "scaled_x_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konvertere til tidserie matrise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definere variabler:\n",
    "n_backward = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for making time series\n",
    "def make_time_series(row_features, look_back_num):\n",
    "    list_of_matrices = []\n",
    "    \n",
    "    num_time_steps = look_back_num + 1\n",
    "    \n",
    "    i = num_time_steps\n",
    "    \n",
    "    while i < len(row_features):\n",
    "        list_of_matrices.append(row_features[(i-num_time_steps):i,:])\n",
    "        \n",
    "        i = i + 1\n",
    "    \n",
    "    return list_of_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_matrix = np.asarray(make_time_series(X_train, n_backward))\n",
    "x_test_matrix = np.asarray(make_time_series(X_test, n_backward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3421, 5, 65)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 65)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_matrix[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fjerne 'n_backward' antall rader, for å få like store sett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_matrix = np.delete(y_train, [x for x in range(n_backward+1)], 0)\n",
    "y_test_matrix = np.delete(y_test, [x for x in range(n_backward+1)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3421,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importere modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_keras_model = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sette opp layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input layer\n",
    "dnn_keras_model.add(layers.LSTM(units=32, return_sequences = True, input_shape=(x_train_matrix.shape[1],x_train_matrix.shape[2]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Hidden Layers'''\n",
    "\n",
    "dnn_keras_model.add(layers.LSTM(units=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "dnn_keras_model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kompilere modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import losses,optimizers,metrics,activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Kompilere - Alternative lossfunctions: mean_squared_error\n",
    "dnn_keras_model.compile(optimizer='adam', loss = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trene modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import losses,optimizers,metrics,activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks og checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=500)\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint('checkpoint_model_LSTM_advanced.h5', monitor = 'val_loss', \n",
    "                                       verbose = 1, save_best_only= True, mode= 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2736 samples, validate on 685 samples\n",
      "Epoch 1/1000\n",
      "Epoch 00000: val_loss improved from inf to 11.21393, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "3s - loss: 12.2046 - val_loss: 11.2139\n",
      "Epoch 2/1000\n",
      "Epoch 00001: val_loss improved from 11.21393 to 10.59710, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.4013 - val_loss: 10.5971\n",
      "Epoch 3/1000\n",
      "Epoch 00002: val_loss improved from 10.59710 to 10.40242, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.2279 - val_loss: 10.4024\n",
      "Epoch 4/1000\n",
      "Epoch 00003: val_loss improved from 10.40242 to 10.28196, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.1618 - val_loss: 10.2820\n",
      "Epoch 5/1000\n",
      "Epoch 00004: val_loss improved from 10.28196 to 10.20929, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.1300 - val_loss: 10.2093\n",
      "Epoch 6/1000\n",
      "Epoch 00005: val_loss improved from 10.20929 to 10.14831, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.1123 - val_loss: 10.1483\n",
      "Epoch 7/1000\n",
      "Epoch 00006: val_loss improved from 10.14831 to 10.11374, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.1037 - val_loss: 10.1137\n",
      "Epoch 8/1000\n",
      "Epoch 00007: val_loss improved from 10.11374 to 10.08508, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "1s - loss: 10.0994 - val_loss: 10.0851\n",
      "Epoch 9/1000\n",
      "Epoch 00008: val_loss improved from 10.08508 to 10.06377, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "1s - loss: 10.0988 - val_loss: 10.0638\n",
      "Epoch 10/1000\n",
      "Epoch 00009: val_loss improved from 10.06377 to 10.05380, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "1s - loss: 10.0953 - val_loss: 10.0538\n",
      "Epoch 11/1000\n",
      "Epoch 00010: val_loss improved from 10.05380 to 10.03340, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0945 - val_loss: 10.0334\n",
      "Epoch 12/1000\n",
      "Epoch 00011: val_loss improved from 10.03340 to 10.03017, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "1s - loss: 10.0943 - val_loss: 10.0302\n",
      "Epoch 13/1000\n",
      "Epoch 00012: val_loss did not improve\n",
      "1s - loss: 10.0937 - val_loss: 10.0304\n",
      "Epoch 14/1000\n",
      "Epoch 00013: val_loss improved from 10.03017 to 10.02753, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "1s - loss: 10.0938 - val_loss: 10.0275\n",
      "Epoch 15/1000\n",
      "Epoch 00014: val_loss improved from 10.02753 to 10.02606, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0932 - val_loss: 10.0261\n",
      "Epoch 16/1000\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 10.0956 - val_loss: 10.0297\n",
      "Epoch 17/1000\n",
      "Epoch 00016: val_loss improved from 10.02606 to 10.01977, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0937 - val_loss: 10.0198\n",
      "Epoch 18/1000\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 10.0935 - val_loss: 10.0423\n",
      "Epoch 19/1000\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 10.0946 - val_loss: 10.0258\n",
      "Epoch 20/1000\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 10.0949 - val_loss: 10.0198\n",
      "Epoch 21/1000\n",
      "Epoch 00020: val_loss improved from 10.01977 to 10.00616, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0964 - val_loss: 10.0062\n",
      "Epoch 22/1000\n",
      "Epoch 00021: val_loss did not improve\n",
      "0s - loss: 10.0943 - val_loss: 10.0103\n",
      "Epoch 23/1000\n",
      "Epoch 00022: val_loss did not improve\n",
      "0s - loss: 10.0943 - val_loss: 10.0205\n",
      "Epoch 24/1000\n",
      "Epoch 00023: val_loss did not improve\n",
      "0s - loss: 10.0949 - val_loss: 10.0239\n",
      "Epoch 25/1000\n",
      "Epoch 00024: val_loss did not improve\n",
      "0s - loss: 10.0945 - val_loss: 10.0107\n",
      "Epoch 26/1000\n",
      "Epoch 00025: val_loss did not improve\n",
      "0s - loss: 10.0946 - val_loss: 10.0222\n",
      "Epoch 27/1000\n",
      "Epoch 00026: val_loss did not improve\n",
      "0s - loss: 10.0936 - val_loss: 10.0180\n",
      "Epoch 28/1000\n",
      "Epoch 00027: val_loss did not improve\n",
      "0s - loss: 10.0935 - val_loss: 10.0212\n",
      "Epoch 29/1000\n",
      "Epoch 00028: val_loss did not improve\n",
      "0s - loss: 10.0936 - val_loss: 10.0210\n",
      "Epoch 30/1000\n",
      "Epoch 00029: val_loss did not improve\n",
      "0s - loss: 10.0950 - val_loss: 10.0233\n",
      "Epoch 31/1000\n",
      "Epoch 00030: val_loss did not improve\n",
      "0s - loss: 10.0930 - val_loss: 10.0387\n",
      "Epoch 32/1000\n",
      "Epoch 00031: val_loss did not improve\n",
      "0s - loss: 10.0963 - val_loss: 10.0244\n",
      "Epoch 33/1000\n",
      "Epoch 00032: val_loss did not improve\n",
      "0s - loss: 10.0939 - val_loss: 10.0147\n",
      "Epoch 34/1000\n",
      "Epoch 00033: val_loss did not improve\n",
      "0s - loss: 10.0958 - val_loss: 10.0310\n",
      "Epoch 35/1000\n",
      "Epoch 00034: val_loss did not improve\n",
      "0s - loss: 10.0943 - val_loss: 10.0088\n",
      "Epoch 36/1000\n",
      "Epoch 00035: val_loss did not improve\n",
      "0s - loss: 10.0943 - val_loss: 10.0231\n",
      "Epoch 37/1000\n",
      "Epoch 00036: val_loss did not improve\n",
      "0s - loss: 10.0932 - val_loss: 10.0206\n",
      "Epoch 38/1000\n",
      "Epoch 00037: val_loss did not improve\n",
      "0s - loss: 10.0937 - val_loss: 10.0213\n",
      "Epoch 39/1000\n",
      "Epoch 00038: val_loss did not improve\n",
      "0s - loss: 10.0937 - val_loss: 10.0295\n",
      "Epoch 40/1000\n",
      "Epoch 00039: val_loss did not improve\n",
      "0s - loss: 10.0929 - val_loss: 10.0269\n",
      "Epoch 41/1000\n",
      "Epoch 00040: val_loss did not improve\n",
      "0s - loss: 10.0934 - val_loss: 10.0378\n",
      "Epoch 42/1000\n",
      "Epoch 00041: val_loss did not improve\n",
      "0s - loss: 10.0941 - val_loss: 10.0161\n",
      "Epoch 43/1000\n",
      "Epoch 00042: val_loss did not improve\n",
      "0s - loss: 10.0943 - val_loss: 10.0238\n",
      "Epoch 44/1000\n",
      "Epoch 00043: val_loss did not improve\n",
      "0s - loss: 10.0938 - val_loss: 10.0236\n",
      "Epoch 45/1000\n",
      "Epoch 00044: val_loss did not improve\n",
      "0s - loss: 10.0943 - val_loss: 10.0115\n",
      "Epoch 46/1000\n",
      "Epoch 00045: val_loss did not improve\n",
      "0s - loss: 10.0931 - val_loss: 10.0309\n",
      "Epoch 47/1000\n",
      "Epoch 00046: val_loss did not improve\n",
      "0s - loss: 10.0930 - val_loss: 10.0282\n",
      "Epoch 48/1000\n",
      "Epoch 00047: val_loss did not improve\n",
      "0s - loss: 10.0933 - val_loss: 10.0416\n",
      "Epoch 49/1000\n",
      "Epoch 00048: val_loss did not improve\n",
      "0s - loss: 10.0932 - val_loss: 10.0325\n",
      "Epoch 50/1000\n",
      "Epoch 00049: val_loss did not improve\n",
      "0s - loss: 10.0924 - val_loss: 10.0545\n",
      "Epoch 51/1000\n",
      "Epoch 00050: val_loss did not improve\n",
      "0s - loss: 10.0941 - val_loss: 10.0224\n",
      "Epoch 52/1000\n",
      "Epoch 00051: val_loss improved from 10.00616 to 9.99825, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.1046 - val_loss: 9.9983\n",
      "Epoch 53/1000\n",
      "Epoch 00052: val_loss did not improve\n",
      "0s - loss: 10.0939 - val_loss: 10.0144\n",
      "Epoch 54/1000\n",
      "Epoch 00053: val_loss did not improve\n",
      "0s - loss: 10.0926 - val_loss: 10.0139\n",
      "Epoch 55/1000\n",
      "Epoch 00054: val_loss did not improve\n",
      "0s - loss: 10.0924 - val_loss: 10.0248\n",
      "Epoch 56/1000\n",
      "Epoch 00055: val_loss did not improve\n",
      "0s - loss: 10.0921 - val_loss: 10.0186\n",
      "Epoch 57/1000\n",
      "Epoch 00056: val_loss did not improve\n",
      "0s - loss: 10.0915 - val_loss: 10.0268\n",
      "Epoch 58/1000\n",
      "Epoch 00057: val_loss did not improve\n",
      "0s - loss: 10.0913 - val_loss: 10.0475\n",
      "Epoch 59/1000\n",
      "Epoch 00058: val_loss did not improve\n",
      "0s - loss: 10.0919 - val_loss: 10.0418\n",
      "Epoch 60/1000\n",
      "Epoch 00059: val_loss did not improve\n",
      "0s - loss: 10.0941 - val_loss: 10.0121\n",
      "Epoch 61/1000\n",
      "Epoch 00060: val_loss did not improve\n",
      "0s - loss: 10.0893 - val_loss: 10.0205\n",
      "Epoch 62/1000\n",
      "Epoch 00061: val_loss did not improve\n",
      "0s - loss: 10.0920 - val_loss: 10.0196\n",
      "Epoch 63/1000\n",
      "Epoch 00062: val_loss did not improve\n",
      "0s - loss: 10.0879 - val_loss: 10.0180\n",
      "Epoch 64/1000\n",
      "Epoch 00063: val_loss did not improve\n",
      "0s - loss: 10.0853 - val_loss: 10.0255\n",
      "Epoch 65/1000\n",
      "Epoch 00064: val_loss did not improve\n",
      "0s - loss: 10.0881 - val_loss: 9.9990\n",
      "Epoch 66/1000\n",
      "Epoch 00065: val_loss did not improve\n",
      "0s - loss: 10.0911 - val_loss: 10.0160\n",
      "Epoch 67/1000\n",
      "Epoch 00066: val_loss did not improve\n",
      "0s - loss: 10.0811 - val_loss: 10.0340\n",
      "Epoch 68/1000\n",
      "Epoch 00067: val_loss did not improve\n",
      "0s - loss: 10.0735 - val_loss: 10.0002\n",
      "Epoch 69/1000\n",
      "Epoch 00068: val_loss did not improve\n",
      "0s - loss: 10.0743 - val_loss: 10.0272\n",
      "Epoch 70/1000\n",
      "Epoch 00069: val_loss did not improve\n",
      "0s - loss: 10.0813 - val_loss: 10.0216\n",
      "Epoch 71/1000\n",
      "Epoch 00070: val_loss improved from 9.99825 to 9.98450, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0763 - val_loss: 9.9845\n",
      "Epoch 72/1000\n",
      "Epoch 00071: val_loss did not improve\n",
      "0s - loss: 10.0791 - val_loss: 10.0074\n",
      "Epoch 73/1000\n",
      "Epoch 00072: val_loss did not improve\n",
      "0s - loss: 10.0762 - val_loss: 10.0316\n",
      "Epoch 74/1000\n",
      "Epoch 00073: val_loss did not improve\n",
      "0s - loss: 10.0777 - val_loss: 10.0224\n",
      "Epoch 75/1000\n",
      "Epoch 00074: val_loss did not improve\n",
      "0s - loss: 10.0715 - val_loss: 10.0574\n",
      "Epoch 76/1000\n",
      "Epoch 00075: val_loss did not improve\n",
      "0s - loss: 10.0768 - val_loss: 10.0088\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00076: val_loss did not improve\n",
      "0s - loss: 10.0699 - val_loss: 10.0257\n",
      "Epoch 78/1000\n",
      "Epoch 00077: val_loss did not improve\n",
      "0s - loss: 10.0708 - val_loss: 10.0143\n",
      "Epoch 79/1000\n",
      "Epoch 00078: val_loss did not improve\n",
      "0s - loss: 10.0748 - val_loss: 10.0315\n",
      "Epoch 80/1000\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 10.0694 - val_loss: 9.9987\n",
      "Epoch 81/1000\n",
      "Epoch 00080: val_loss improved from 9.98450 to 9.97934, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0807 - val_loss: 9.9793\n",
      "Epoch 82/1000\n",
      "Epoch 00081: val_loss did not improve\n",
      "0s - loss: 10.0752 - val_loss: 10.0207\n",
      "Epoch 83/1000\n",
      "Epoch 00082: val_loss did not improve\n",
      "0s - loss: 10.0715 - val_loss: 10.0373\n",
      "Epoch 84/1000\n",
      "Epoch 00083: val_loss did not improve\n",
      "0s - loss: 10.0708 - val_loss: 10.0447\n",
      "Epoch 85/1000\n",
      "Epoch 00084: val_loss did not improve\n",
      "0s - loss: 10.0687 - val_loss: 9.9964\n",
      "Epoch 86/1000\n",
      "Epoch 00085: val_loss did not improve\n",
      "0s - loss: 10.0698 - val_loss: 10.0018\n",
      "Epoch 87/1000\n",
      "Epoch 00086: val_loss did not improve\n",
      "0s - loss: 10.0735 - val_loss: 9.9812\n",
      "Epoch 88/1000\n",
      "Epoch 00087: val_loss did not improve\n",
      "0s - loss: 10.0690 - val_loss: 10.0087\n",
      "Epoch 89/1000\n",
      "Epoch 00088: val_loss did not improve\n",
      "0s - loss: 10.0722 - val_loss: 9.9855\n",
      "Epoch 90/1000\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 10.0670 - val_loss: 10.0205\n",
      "Epoch 91/1000\n",
      "Epoch 00090: val_loss did not improve\n",
      "0s - loss: 10.0684 - val_loss: 10.0699\n",
      "Epoch 92/1000\n",
      "Epoch 00091: val_loss did not improve\n",
      "0s - loss: 10.0774 - val_loss: 10.0193\n",
      "Epoch 93/1000\n",
      "Epoch 00092: val_loss did not improve\n",
      "0s - loss: 10.0722 - val_loss: 10.0289\n",
      "Epoch 94/1000\n",
      "Epoch 00093: val_loss improved from 9.97934 to 9.97385, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0743 - val_loss: 9.9739\n",
      "Epoch 95/1000\n",
      "Epoch 00094: val_loss did not improve\n",
      "0s - loss: 10.0705 - val_loss: 9.9906\n",
      "Epoch 96/1000\n",
      "Epoch 00095: val_loss did not improve\n",
      "0s - loss: 10.0724 - val_loss: 9.9948\n",
      "Epoch 97/1000\n",
      "Epoch 00096: val_loss did not improve\n",
      "0s - loss: 10.0701 - val_loss: 10.0393\n",
      "Epoch 98/1000\n",
      "Epoch 00097: val_loss did not improve\n",
      "0s - loss: 10.0670 - val_loss: 10.0773\n",
      "Epoch 99/1000\n",
      "Epoch 00098: val_loss did not improve\n",
      "0s - loss: 10.0700 - val_loss: 10.0155\n",
      "Epoch 100/1000\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 10.0655 - val_loss: 9.9850\n",
      "Epoch 101/1000\n",
      "Epoch 00100: val_loss did not improve\n",
      "0s - loss: 10.0683 - val_loss: 9.9959\n",
      "Epoch 102/1000\n",
      "Epoch 00101: val_loss did not improve\n",
      "0s - loss: 10.0671 - val_loss: 10.0228\n",
      "Epoch 103/1000\n",
      "Epoch 00102: val_loss improved from 9.97385 to 9.96614, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0706 - val_loss: 9.9661\n",
      "Epoch 104/1000\n",
      "Epoch 00103: val_loss did not improve\n",
      "0s - loss: 10.0694 - val_loss: 10.0113\n",
      "Epoch 105/1000\n",
      "Epoch 00104: val_loss did not improve\n",
      "0s - loss: 10.0664 - val_loss: 9.9832\n",
      "Epoch 106/1000\n",
      "Epoch 00105: val_loss did not improve\n",
      "0s - loss: 10.0667 - val_loss: 9.9940\n",
      "Epoch 107/1000\n",
      "Epoch 00106: val_loss did not improve\n",
      "0s - loss: 10.0649 - val_loss: 9.9734\n",
      "Epoch 108/1000\n",
      "Epoch 00107: val_loss did not improve\n",
      "0s - loss: 10.0666 - val_loss: 9.9939\n",
      "Epoch 109/1000\n",
      "Epoch 00108: val_loss did not improve\n",
      "0s - loss: 10.0650 - val_loss: 9.9912\n",
      "Epoch 110/1000\n",
      "Epoch 00109: val_loss improved from 9.96614 to 9.96433, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0676 - val_loss: 9.9643\n",
      "Epoch 111/1000\n",
      "Epoch 00110: val_loss did not improve\n",
      "0s - loss: 10.0685 - val_loss: 9.9852\n",
      "Epoch 112/1000\n",
      "Epoch 00111: val_loss did not improve\n",
      "0s - loss: 10.0679 - val_loss: 9.9911\n",
      "Epoch 113/1000\n",
      "Epoch 00112: val_loss did not improve\n",
      "0s - loss: 10.0639 - val_loss: 9.9970\n",
      "Epoch 114/1000\n",
      "Epoch 00113: val_loss did not improve\n",
      "0s - loss: 10.0641 - val_loss: 10.0042\n",
      "Epoch 115/1000\n",
      "Epoch 00114: val_loss did not improve\n",
      "0s - loss: 10.0640 - val_loss: 9.9861\n",
      "Epoch 116/1000\n",
      "Epoch 00115: val_loss did not improve\n",
      "0s - loss: 10.0654 - val_loss: 9.9968\n",
      "Epoch 117/1000\n",
      "Epoch 00116: val_loss did not improve\n",
      "0s - loss: 10.0634 - val_loss: 9.9907\n",
      "Epoch 118/1000\n",
      "Epoch 00117: val_loss did not improve\n",
      "0s - loss: 10.0652 - val_loss: 10.0243\n",
      "Epoch 119/1000\n",
      "Epoch 00118: val_loss did not improve\n",
      "0s - loss: 10.0636 - val_loss: 9.9752\n",
      "Epoch 120/1000\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 10.0713 - val_loss: 9.9875\n",
      "Epoch 121/1000\n",
      "Epoch 00120: val_loss did not improve\n",
      "0s - loss: 10.0721 - val_loss: 10.0064\n",
      "Epoch 122/1000\n",
      "Epoch 00121: val_loss did not improve\n",
      "0s - loss: 10.0667 - val_loss: 9.9785\n",
      "Epoch 123/1000\n",
      "Epoch 00122: val_loss did not improve\n",
      "0s - loss: 10.0667 - val_loss: 10.0105\n",
      "Epoch 124/1000\n",
      "Epoch 00123: val_loss did not improve\n",
      "0s - loss: 10.0662 - val_loss: 9.9649\n",
      "Epoch 125/1000\n",
      "Epoch 00124: val_loss did not improve\n",
      "0s - loss: 10.0589 - val_loss: 10.0741\n",
      "Epoch 126/1000\n",
      "Epoch 00125: val_loss improved from 9.96433 to 9.95460, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0709 - val_loss: 9.9546\n",
      "Epoch 127/1000\n",
      "Epoch 00126: val_loss did not improve\n",
      "0s - loss: 10.0692 - val_loss: 9.9953\n",
      "Epoch 128/1000\n",
      "Epoch 00127: val_loss did not improve\n",
      "0s - loss: 10.0638 - val_loss: 9.9743\n",
      "Epoch 129/1000\n",
      "Epoch 00128: val_loss did not improve\n",
      "0s - loss: 10.0662 - val_loss: 9.9888\n",
      "Epoch 130/1000\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 10.0636 - val_loss: 9.9976\n",
      "Epoch 131/1000\n",
      "Epoch 00130: val_loss did not improve\n",
      "0s - loss: 10.0656 - val_loss: 10.0029\n",
      "Epoch 132/1000\n",
      "Epoch 00131: val_loss did not improve\n",
      "0s - loss: 10.0654 - val_loss: 10.0074\n",
      "Epoch 133/1000\n",
      "Epoch 00132: val_loss did not improve\n",
      "0s - loss: 10.0653 - val_loss: 10.0108\n",
      "Epoch 134/1000\n",
      "Epoch 00133: val_loss did not improve\n",
      "0s - loss: 10.0651 - val_loss: 10.0268\n",
      "Epoch 135/1000\n",
      "Epoch 00134: val_loss did not improve\n",
      "0s - loss: 10.0656 - val_loss: 10.0133\n",
      "Epoch 136/1000\n",
      "Epoch 00135: val_loss did not improve\n",
      "0s - loss: 10.0640 - val_loss: 9.9780\n",
      "Epoch 137/1000\n",
      "Epoch 00136: val_loss did not improve\n",
      "0s - loss: 10.0644 - val_loss: 9.9895\n",
      "Epoch 138/1000\n",
      "Epoch 00137: val_loss did not improve\n",
      "0s - loss: 10.0643 - val_loss: 9.9833\n",
      "Epoch 139/1000\n",
      "Epoch 00138: val_loss did not improve\n",
      "0s - loss: 10.0658 - val_loss: 10.0104\n",
      "Epoch 140/1000\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 10.0629 - val_loss: 10.0089\n",
      "Epoch 141/1000\n",
      "Epoch 00140: val_loss did not improve\n",
      "0s - loss: 10.0657 - val_loss: 10.0159\n",
      "Epoch 142/1000\n",
      "Epoch 00141: val_loss did not improve\n",
      "0s - loss: 10.0621 - val_loss: 10.0393\n",
      "Epoch 143/1000\n",
      "Epoch 00142: val_loss did not improve\n",
      "0s - loss: 10.0658 - val_loss: 9.9785\n",
      "Epoch 144/1000\n",
      "Epoch 00143: val_loss did not improve\n",
      "0s - loss: 10.0654 - val_loss: 10.0129\n",
      "Epoch 145/1000\n",
      "Epoch 00144: val_loss did not improve\n",
      "0s - loss: 10.0665 - val_loss: 10.0271\n",
      "Epoch 146/1000\n",
      "Epoch 00145: val_loss did not improve\n",
      "0s - loss: 10.0623 - val_loss: 10.0180\n",
      "Epoch 147/1000\n",
      "Epoch 00146: val_loss did not improve\n",
      "0s - loss: 10.0657 - val_loss: 9.9923\n",
      "Epoch 148/1000\n",
      "Epoch 00147: val_loss did not improve\n",
      "0s - loss: 10.0644 - val_loss: 10.0120\n",
      "Epoch 149/1000\n",
      "Epoch 00148: val_loss did not improve\n",
      "0s - loss: 10.0639 - val_loss: 10.0130\n",
      "Epoch 150/1000\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 10.0686 - val_loss: 10.0113\n",
      "Epoch 151/1000\n",
      "Epoch 00150: val_loss did not improve\n",
      "0s - loss: 10.0669 - val_loss: 9.9974\n",
      "Epoch 152/1000\n",
      "Epoch 00151: val_loss did not improve\n",
      "0s - loss: 10.0620 - val_loss: 9.9947\n",
      "Epoch 153/1000\n",
      "Epoch 00152: val_loss did not improve\n",
      "0s - loss: 10.0614 - val_loss: 10.0524\n",
      "Epoch 154/1000\n",
      "Epoch 00153: val_loss improved from 9.95460 to 9.95403, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0608 - val_loss: 9.9540\n",
      "Epoch 155/1000\n",
      "Epoch 00154: val_loss did not improve\n",
      "0s - loss: 10.0640 - val_loss: 9.9895\n",
      "Epoch 156/1000\n",
      "Epoch 00155: val_loss did not improve\n",
      "0s - loss: 10.0622 - val_loss: 9.9853\n",
      "Epoch 157/1000\n",
      "Epoch 00156: val_loss did not improve\n",
      "0s - loss: 10.0629 - val_loss: 9.9833\n",
      "Epoch 158/1000\n",
      "Epoch 00157: val_loss did not improve\n",
      "0s - loss: 10.0640 - val_loss: 9.9936\n",
      "Epoch 159/1000\n",
      "Epoch 00158: val_loss did not improve\n",
      "0s - loss: 10.0652 - val_loss: 9.9718\n",
      "Epoch 160/1000\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 10.0613 - val_loss: 10.0148\n",
      "Epoch 161/1000\n",
      "Epoch 00160: val_loss did not improve\n",
      "0s - loss: 10.0628 - val_loss: 10.0146\n",
      "Epoch 162/1000\n",
      "Epoch 00161: val_loss did not improve\n",
      "0s - loss: 10.0639 - val_loss: 9.9792\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00162: val_loss improved from 9.95403 to 9.95073, saving model to checkpoint_model_LSTM_advanced.h5\n",
      "0s - loss: 10.0655 - val_loss: 9.9507\n",
      "Epoch 164/1000\n",
      "Epoch 00163: val_loss did not improve\n",
      "0s - loss: 10.0647 - val_loss: 9.9939\n",
      "Epoch 165/1000\n",
      "Epoch 00164: val_loss did not improve\n",
      "0s - loss: 10.0611 - val_loss: 10.0059\n",
      "Epoch 166/1000\n",
      "Epoch 00165: val_loss did not improve\n",
      "0s - loss: 10.0626 - val_loss: 10.0110\n",
      "Epoch 167/1000\n",
      "Epoch 00166: val_loss did not improve\n",
      "0s - loss: 10.0637 - val_loss: 9.9922\n",
      "Epoch 168/1000\n",
      "Epoch 00167: val_loss did not improve\n",
      "1s - loss: 10.0621 - val_loss: 9.9979\n",
      "Epoch 169/1000\n",
      "Epoch 00168: val_loss did not improve\n",
      "0s - loss: 10.0611 - val_loss: 10.0114\n",
      "Epoch 170/1000\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 10.0633 - val_loss: 9.9677\n",
      "Epoch 171/1000\n",
      "Epoch 00170: val_loss did not improve\n",
      "0s - loss: 10.0641 - val_loss: 9.9989\n",
      "Epoch 172/1000\n",
      "Epoch 00171: val_loss did not improve\n",
      "0s - loss: 10.0631 - val_loss: 9.9776\n",
      "Epoch 173/1000\n",
      "Epoch 00172: val_loss did not improve\n",
      "0s - loss: 10.0621 - val_loss: 10.0045\n",
      "Epoch 174/1000\n",
      "Epoch 00173: val_loss did not improve\n",
      "1s - loss: 10.0657 - val_loss: 10.0482\n",
      "Epoch 175/1000\n",
      "Epoch 00174: val_loss did not improve\n",
      "0s - loss: 10.0642 - val_loss: 10.0122\n",
      "Epoch 176/1000\n",
      "Epoch 00175: val_loss did not improve\n",
      "0s - loss: 10.0617 - val_loss: 9.9984\n",
      "Epoch 177/1000\n",
      "Epoch 00176: val_loss did not improve\n",
      "1s - loss: 10.0597 - val_loss: 10.0121\n",
      "Epoch 178/1000\n",
      "Epoch 00177: val_loss did not improve\n",
      "0s - loss: 10.0646 - val_loss: 9.9996\n",
      "Epoch 179/1000\n",
      "Epoch 00178: val_loss did not improve\n",
      "0s - loss: 10.0633 - val_loss: 10.0034\n",
      "Epoch 180/1000\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 10.0646 - val_loss: 10.0042\n",
      "Epoch 181/1000\n",
      "Epoch 00180: val_loss did not improve\n",
      "0s - loss: 10.0641 - val_loss: 10.0303\n",
      "Epoch 182/1000\n",
      "Epoch 00181: val_loss did not improve\n",
      "0s - loss: 10.0620 - val_loss: 9.9880\n",
      "Epoch 183/1000\n",
      "Epoch 00182: val_loss did not improve\n",
      "0s - loss: 10.0621 - val_loss: 10.0029\n",
      "Epoch 184/1000\n",
      "Epoch 00183: val_loss did not improve\n",
      "0s - loss: 10.0618 - val_loss: 9.9875\n",
      "Epoch 185/1000\n",
      "Epoch 00184: val_loss did not improve\n",
      "0s - loss: 10.0628 - val_loss: 9.9963\n",
      "Epoch 186/1000\n",
      "Epoch 00185: val_loss did not improve\n",
      "0s - loss: 10.0606 - val_loss: 10.0098\n",
      "Epoch 187/1000\n",
      "Epoch 00186: val_loss did not improve\n",
      "0s - loss: 10.0630 - val_loss: 10.0101\n",
      "Epoch 188/1000\n",
      "Epoch 00187: val_loss did not improve\n",
      "0s - loss: 10.0616 - val_loss: 9.9959\n",
      "Epoch 189/1000\n",
      "Epoch 00188: val_loss did not improve\n",
      "0s - loss: 10.0619 - val_loss: 9.9881\n",
      "Epoch 190/1000\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 10.0684 - val_loss: 9.9677\n",
      "Epoch 191/1000\n",
      "Epoch 00190: val_loss did not improve\n",
      "0s - loss: 10.0634 - val_loss: 10.0166\n",
      "Epoch 192/1000\n",
      "Epoch 00191: val_loss did not improve\n",
      "0s - loss: 10.0642 - val_loss: 9.9943\n",
      "Epoch 193/1000\n",
      "Epoch 00192: val_loss did not improve\n",
      "0s - loss: 10.0623 - val_loss: 9.9892\n",
      "Epoch 194/1000\n",
      "Epoch 00193: val_loss did not improve\n",
      "0s - loss: 10.0613 - val_loss: 10.0260\n",
      "Epoch 195/1000\n",
      "Epoch 00194: val_loss did not improve\n",
      "0s - loss: 10.0607 - val_loss: 10.0092\n",
      "Epoch 196/1000\n",
      "Epoch 00195: val_loss did not improve\n",
      "0s - loss: 10.0600 - val_loss: 9.9810\n",
      "Epoch 197/1000\n",
      "Epoch 00196: val_loss did not improve\n",
      "0s - loss: 10.0623 - val_loss: 9.9778\n",
      "Epoch 198/1000\n",
      "Epoch 00197: val_loss did not improve\n",
      "0s - loss: 10.0611 - val_loss: 10.0033\n",
      "Epoch 199/1000\n",
      "Epoch 00198: val_loss did not improve\n",
      "0s - loss: 10.0648 - val_loss: 9.9918\n",
      "Epoch 200/1000\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 10.0609 - val_loss: 10.0079\n",
      "Epoch 201/1000\n",
      "Epoch 00200: val_loss did not improve\n",
      "0s - loss: 10.0611 - val_loss: 9.9964\n",
      "Epoch 202/1000\n",
      "Epoch 00201: val_loss did not improve\n",
      "0s - loss: 10.0611 - val_loss: 10.0085\n",
      "Epoch 203/1000\n",
      "Epoch 00202: val_loss did not improve\n",
      "0s - loss: 10.0604 - val_loss: 9.9971\n",
      "Epoch 204/1000\n",
      "Epoch 00203: val_loss did not improve\n",
      "0s - loss: 10.0628 - val_loss: 10.0028\n",
      "Epoch 205/1000\n",
      "Epoch 00204: val_loss did not improve\n",
      "0s - loss: 10.0632 - val_loss: 9.9985\n",
      "Epoch 206/1000\n",
      "Epoch 00205: val_loss did not improve\n",
      "0s - loss: 10.0615 - val_loss: 9.9965\n",
      "Epoch 207/1000\n",
      "Epoch 00206: val_loss did not improve\n",
      "0s - loss: 10.0616 - val_loss: 9.9957\n",
      "Epoch 208/1000\n",
      "Epoch 00207: val_loss did not improve\n",
      "0s - loss: 10.0615 - val_loss: 10.0157\n",
      "Epoch 209/1000\n",
      "Epoch 00208: val_loss did not improve\n",
      "0s - loss: 10.0598 - val_loss: 9.9934\n",
      "Epoch 210/1000\n",
      "Epoch 00209: val_loss did not improve\n",
      "0s - loss: 10.0629 - val_loss: 9.9858\n",
      "Epoch 211/1000\n",
      "Epoch 00210: val_loss did not improve\n",
      "0s - loss: 10.0617 - val_loss: 9.9973\n",
      "Epoch 212/1000\n",
      "Epoch 00211: val_loss did not improve\n",
      "0s - loss: 10.0612 - val_loss: 10.0109\n",
      "Epoch 213/1000\n",
      "Epoch 00212: val_loss did not improve\n",
      "0s - loss: 10.0606 - val_loss: 9.9937\n",
      "Epoch 214/1000\n",
      "Epoch 00213: val_loss did not improve\n",
      "0s - loss: 10.0593 - val_loss: 9.9783\n",
      "Epoch 215/1000\n",
      "Epoch 00214: val_loss did not improve\n",
      "0s - loss: 10.0642 - val_loss: 9.9795\n",
      "Epoch 216/1000\n",
      "Epoch 00215: val_loss did not improve\n",
      "0s - loss: 10.0615 - val_loss: 9.9800\n",
      "Epoch 217/1000\n",
      "Epoch 00216: val_loss did not improve\n",
      "0s - loss: 10.0598 - val_loss: 10.0053\n",
      "Epoch 218/1000\n",
      "Epoch 00217: val_loss did not improve\n",
      "0s - loss: 10.0612 - val_loss: 10.0202\n",
      "Epoch 219/1000\n",
      "Epoch 00218: val_loss did not improve\n",
      "0s - loss: 10.0627 - val_loss: 10.0359\n",
      "Epoch 220/1000\n",
      "Epoch 00219: val_loss did not improve\n",
      "0s - loss: 10.0626 - val_loss: 9.9939\n",
      "Epoch 221/1000\n",
      "Epoch 00220: val_loss did not improve\n",
      "0s - loss: 10.0611 - val_loss: 9.9767\n",
      "Epoch 222/1000\n",
      "Epoch 00221: val_loss did not improve\n",
      "0s - loss: 10.0632 - val_loss: 9.9871\n",
      "Epoch 223/1000\n",
      "Epoch 00222: val_loss did not improve\n",
      "0s - loss: 10.0637 - val_loss: 9.9872\n",
      "Epoch 224/1000\n",
      "Epoch 00223: val_loss did not improve\n",
      "0s - loss: 10.0618 - val_loss: 9.9888\n",
      "Epoch 225/1000\n",
      "Epoch 00224: val_loss did not improve\n",
      "0s - loss: 10.0622 - val_loss: 9.9874\n",
      "Epoch 226/1000\n",
      "Epoch 00225: val_loss did not improve\n",
      "0s - loss: 10.0611 - val_loss: 10.0039\n",
      "Epoch 227/1000\n",
      "Epoch 00226: val_loss did not improve\n",
      "0s - loss: 10.0625 - val_loss: 9.9881\n",
      "Epoch 228/1000\n",
      "Epoch 00227: val_loss did not improve\n",
      "0s - loss: 10.0652 - val_loss: 10.0064\n",
      "Epoch 229/1000\n",
      "Epoch 00228: val_loss did not improve\n",
      "0s - loss: 10.0594 - val_loss: 10.0141\n",
      "Epoch 230/1000\n",
      "Epoch 00229: val_loss did not improve\n",
      "0s - loss: 10.0607 - val_loss: 10.0183\n",
      "Epoch 231/1000\n",
      "Epoch 00230: val_loss did not improve\n",
      "0s - loss: 10.0631 - val_loss: 9.9996\n",
      "Epoch 232/1000\n",
      "Epoch 00231: val_loss did not improve\n",
      "0s - loss: 10.0607 - val_loss: 9.9984\n",
      "Epoch 233/1000\n",
      "Epoch 00232: val_loss did not improve\n",
      "0s - loss: 10.0621 - val_loss: 10.0004\n",
      "Epoch 234/1000\n",
      "Epoch 00233: val_loss did not improve\n",
      "0s - loss: 10.0606 - val_loss: 10.0096\n",
      "Epoch 235/1000\n",
      "Epoch 00234: val_loss did not improve\n",
      "0s - loss: 10.0617 - val_loss: 10.0200\n",
      "Epoch 236/1000\n",
      "Epoch 00235: val_loss did not improve\n",
      "0s - loss: 10.0613 - val_loss: 10.0042\n",
      "Epoch 237/1000\n",
      "Epoch 00236: val_loss did not improve\n",
      "0s - loss: 10.0594 - val_loss: 10.0042\n",
      "Epoch 238/1000\n",
      "Epoch 00237: val_loss did not improve\n",
      "0s - loss: 10.0603 - val_loss: 9.9965\n",
      "Epoch 239/1000\n",
      "Epoch 00238: val_loss did not improve\n",
      "0s - loss: 10.0608 - val_loss: 10.0035\n",
      "Epoch 240/1000\n",
      "Epoch 00239: val_loss did not improve\n",
      "0s - loss: 10.0616 - val_loss: 9.9780\n",
      "Epoch 241/1000\n",
      "Epoch 00240: val_loss did not improve\n",
      "0s - loss: 10.0619 - val_loss: 10.0122\n",
      "Epoch 242/1000\n",
      "Epoch 00241: val_loss did not improve\n",
      "0s - loss: 10.0619 - val_loss: 10.0169\n",
      "Epoch 243/1000\n",
      "Epoch 00242: val_loss did not improve\n",
      "0s - loss: 10.0621 - val_loss: 10.0149\n",
      "Epoch 244/1000\n",
      "Epoch 00243: val_loss did not improve\n",
      "0s - loss: 10.0652 - val_loss: 10.0036\n",
      "Epoch 245/1000\n",
      "Epoch 00244: val_loss did not improve\n",
      "0s - loss: 10.0604 - val_loss: 10.0154\n",
      "Epoch 246/1000\n",
      "Epoch 00245: val_loss did not improve\n",
      "0s - loss: 10.0596 - val_loss: 9.9840\n",
      "Epoch 247/1000\n",
      "Epoch 00246: val_loss did not improve\n",
      "0s - loss: 10.0617 - val_loss: 9.9849\n",
      "Epoch 248/1000\n",
      "Epoch 00247: val_loss did not improve\n",
      "0s - loss: 10.0629 - val_loss: 10.0133\n",
      "Epoch 249/1000\n",
      "Epoch 00248: val_loss did not improve\n",
      "0s - loss: 10.0623 - val_loss: 9.9952\n",
      "Epoch 250/1000\n",
      "Epoch 00249: val_loss did not improve\n",
      "0s - loss: 10.0624 - val_loss: 10.0100\n",
      "Epoch 251/1000\n",
      "Epoch 00250: val_loss did not improve\n",
      "0s - loss: 10.0598 - val_loss: 9.9880\n",
      "Epoch 252/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00251: val_loss did not improve\n",
      "0s - loss: 10.0617 - val_loss: 10.0063\n",
      "Epoch 253/1000\n",
      "Epoch 00252: val_loss did not improve\n",
      "0s - loss: 10.0588 - val_loss: 9.9843\n",
      "Epoch 254/1000\n",
      "Epoch 00253: val_loss did not improve\n",
      "0s - loss: 10.0615 - val_loss: 9.9900\n",
      "Epoch 255/1000\n",
      "Epoch 00254: val_loss did not improve\n",
      "0s - loss: 10.0624 - val_loss: 10.0332\n",
      "Epoch 256/1000\n",
      "Epoch 00255: val_loss did not improve\n",
      "0s - loss: 10.0601 - val_loss: 10.0180\n",
      "Epoch 257/1000\n",
      "Epoch 00256: val_loss did not improve\n",
      "0s - loss: 10.0603 - val_loss: 9.9806\n",
      "Epoch 258/1000\n",
      "Epoch 00257: val_loss did not improve\n",
      "0s - loss: 10.0617 - val_loss: 9.9836\n",
      "Epoch 259/1000\n",
      "Epoch 00258: val_loss did not improve\n",
      "1s - loss: 10.0600 - val_loss: 9.9901\n",
      "Epoch 260/1000\n",
      "Epoch 00259: val_loss did not improve\n",
      "0s - loss: 10.0602 - val_loss: 10.0227\n",
      "Epoch 261/1000\n",
      "Epoch 00260: val_loss did not improve\n",
      "0s - loss: 10.0643 - val_loss: 10.0086\n",
      "Epoch 262/1000\n",
      "Epoch 00261: val_loss did not improve\n",
      "0s - loss: 10.0617 - val_loss: 10.0392\n",
      "Epoch 263/1000\n",
      "Epoch 00262: val_loss did not improve\n",
      "0s - loss: 10.0601 - val_loss: 9.9925\n",
      "Epoch 264/1000\n",
      "Epoch 00263: val_loss did not improve\n",
      "0s - loss: 10.0594 - val_loss: 9.9877\n",
      "Epoch 265/1000\n",
      "Epoch 00264: val_loss did not improve\n",
      "0s - loss: 10.0604 - val_loss: 9.9872\n",
      "Epoch 266/1000\n",
      "Epoch 00265: val_loss did not improve\n",
      "0s - loss: 10.0595 - val_loss: 9.9998\n",
      "Epoch 267/1000\n",
      "Epoch 00266: val_loss did not improve\n",
      "0s - loss: 10.0611 - val_loss: 10.0063\n",
      "Epoch 268/1000\n",
      "Epoch 00267: val_loss did not improve\n",
      "0s - loss: 10.0593 - val_loss: 9.9987\n",
      "Epoch 269/1000\n",
      "Epoch 00268: val_loss did not improve\n",
      "0s - loss: 10.0597 - val_loss: 10.0005\n",
      "Epoch 270/1000\n",
      "Epoch 00269: val_loss did not improve\n",
      "0s - loss: 10.0609 - val_loss: 9.9742\n",
      "Epoch 271/1000\n",
      "Epoch 00270: val_loss did not improve\n",
      "0s - loss: 10.0604 - val_loss: 10.0060\n",
      "Epoch 272/1000\n",
      "Epoch 00271: val_loss did not improve\n",
      "0s - loss: 10.0591 - val_loss: 10.0019\n",
      "Epoch 273/1000\n",
      "Epoch 00272: val_loss did not improve\n",
      "0s - loss: 10.0588 - val_loss: 10.0108\n",
      "Epoch 274/1000\n",
      "Epoch 00273: val_loss did not improve\n",
      "0s - loss: 10.0593 - val_loss: 10.0077\n",
      "Epoch 275/1000\n",
      "Epoch 00274: val_loss did not improve\n",
      "0s - loss: 10.0606 - val_loss: 10.0061\n",
      "Epoch 276/1000\n",
      "Epoch 00275: val_loss did not improve\n",
      "0s - loss: 10.0618 - val_loss: 9.9792\n",
      "Epoch 277/1000\n",
      "Epoch 00276: val_loss did not improve\n",
      "0s - loss: 10.0592 - val_loss: 9.9900\n",
      "Epoch 278/1000\n",
      "Epoch 00277: val_loss did not improve\n",
      "0s - loss: 10.0585 - val_loss: 9.9971\n",
      "Epoch 279/1000\n",
      "Epoch 00278: val_loss did not improve\n",
      "0s - loss: 10.0617 - val_loss: 9.9842\n",
      "Epoch 280/1000\n",
      "Epoch 00279: val_loss did not improve\n",
      "0s - loss: 10.0605 - val_loss: 10.0016\n",
      "Epoch 281/1000\n",
      "Epoch 00280: val_loss did not improve\n",
      "0s - loss: 10.0612 - val_loss: 10.0101\n",
      "Epoch 282/1000\n",
      "Epoch 00281: val_loss did not improve\n",
      "0s - loss: 10.0632 - val_loss: 9.9704\n",
      "Epoch 283/1000\n",
      "Epoch 00282: val_loss did not improve\n",
      "0s - loss: 10.0603 - val_loss: 10.0056\n",
      "Epoch 284/1000\n",
      "Epoch 00283: val_loss did not improve\n",
      "0s - loss: 10.0601 - val_loss: 9.9932\n",
      "Epoch 285/1000\n",
      "Epoch 00284: val_loss did not improve\n",
      "0s - loss: 10.0593 - val_loss: 10.0045\n",
      "Epoch 286/1000\n",
      "Epoch 00285: val_loss did not improve\n",
      "0s - loss: 10.0618 - val_loss: 9.9851\n",
      "Epoch 287/1000\n",
      "Epoch 00286: val_loss did not improve\n",
      "0s - loss: 10.0600 - val_loss: 9.9980\n",
      "Epoch 288/1000\n",
      "Epoch 00287: val_loss did not improve\n",
      "0s - loss: 10.0592 - val_loss: 9.9972\n",
      "Epoch 289/1000\n",
      "Epoch 00288: val_loss did not improve\n",
      "0s - loss: 10.0588 - val_loss: 10.0120\n",
      "Epoch 290/1000\n",
      "Epoch 00289: val_loss did not improve\n",
      "0s - loss: 10.0612 - val_loss: 9.9858\n",
      "Epoch 291/1000\n",
      "Epoch 00290: val_loss did not improve\n",
      "0s - loss: 10.0618 - val_loss: 10.0193\n",
      "Epoch 292/1000\n",
      "Epoch 00291: val_loss did not improve\n",
      "0s - loss: 10.0595 - val_loss: 9.9895\n",
      "Epoch 293/1000\n",
      "Epoch 00292: val_loss did not improve\n",
      "0s - loss: 10.0599 - val_loss: 10.0204\n",
      "Epoch 294/1000\n",
      "Epoch 00293: val_loss did not improve\n",
      "0s - loss: 10.0605 - val_loss: 10.0058\n",
      "Epoch 295/1000\n",
      "Epoch 00294: val_loss did not improve\n",
      "0s - loss: 10.0592 - val_loss: 9.9842\n",
      "Epoch 296/1000\n",
      "Epoch 00295: val_loss did not improve\n",
      "0s - loss: 10.0625 - val_loss: 10.0086\n",
      "Epoch 297/1000\n",
      "Epoch 00296: val_loss did not improve\n",
      "0s - loss: 10.0601 - val_loss: 10.0016\n",
      "Epoch 298/1000\n",
      "Epoch 00297: val_loss did not improve\n",
      "0s - loss: 10.0603 - val_loss: 9.9766\n",
      "Epoch 299/1000\n",
      "Epoch 00298: val_loss did not improve\n",
      "0s - loss: 10.0590 - val_loss: 9.9897\n",
      "Epoch 300/1000\n",
      "Epoch 00299: val_loss did not improve\n",
      "0s - loss: 10.0586 - val_loss: 10.0181\n",
      "Epoch 301/1000\n",
      "Epoch 00300: val_loss did not improve\n",
      "0s - loss: 10.0599 - val_loss: 9.9917\n",
      "Epoch 302/1000\n",
      "Epoch 00301: val_loss did not improve\n",
      "0s - loss: 10.0589 - val_loss: 10.0026\n",
      "Epoch 303/1000\n",
      "Epoch 00302: val_loss did not improve\n",
      "0s - loss: 10.0589 - val_loss: 9.9804\n",
      "Epoch 304/1000\n",
      "Epoch 00303: val_loss did not improve\n",
      "0s - loss: 10.0604 - val_loss: 9.9932\n",
      "Epoch 305/1000\n",
      "Epoch 00304: val_loss did not improve\n",
      "0s - loss: 10.0591 - val_loss: 10.0235\n",
      "Epoch 306/1000\n",
      "Epoch 00305: val_loss did not improve\n",
      "0s - loss: 10.0605 - val_loss: 10.0087\n",
      "Epoch 307/1000\n",
      "Epoch 00306: val_loss did not improve\n",
      "0s - loss: 10.0602 - val_loss: 9.9852\n",
      "Epoch 308/1000\n",
      "Epoch 00307: val_loss did not improve\n",
      "0s - loss: 10.0619 - val_loss: 9.9832\n",
      "Epoch 309/1000\n",
      "Epoch 00308: val_loss did not improve\n",
      "0s - loss: 10.0593 - val_loss: 9.9821\n",
      "Epoch 310/1000\n",
      "Epoch 00309: val_loss did not improve\n",
      "0s - loss: 10.0601 - val_loss: 9.9805\n",
      "Epoch 311/1000\n",
      "Epoch 00310: val_loss did not improve\n",
      "0s - loss: 10.0623 - val_loss: 9.9852\n",
      "Epoch 312/1000\n",
      "Epoch 00311: val_loss did not improve\n",
      "0s - loss: 10.0632 - val_loss: 9.9701\n",
      "Epoch 313/1000\n",
      "Epoch 00312: val_loss did not improve\n",
      "0s - loss: 10.0626 - val_loss: 9.9959\n",
      "Epoch 314/1000\n",
      "Epoch 00313: val_loss did not improve\n",
      "0s - loss: 10.0596 - val_loss: 9.9893\n",
      "Epoch 315/1000\n",
      "Epoch 00314: val_loss did not improve\n",
      "0s - loss: 10.0591 - val_loss: 9.9791\n",
      "Epoch 316/1000\n",
      "Epoch 00315: val_loss did not improve\n",
      "0s - loss: 10.0590 - val_loss: 10.0026\n",
      "Epoch 317/1000\n",
      "Epoch 00316: val_loss did not improve\n",
      "0s - loss: 10.0622 - val_loss: 10.0026\n",
      "Epoch 318/1000\n",
      "Epoch 00317: val_loss did not improve\n",
      "0s - loss: 10.0603 - val_loss: 10.0074\n",
      "Epoch 319/1000\n",
      "Epoch 00318: val_loss did not improve\n",
      "0s - loss: 10.0580 - val_loss: 9.9937\n",
      "Epoch 320/1000\n",
      "Epoch 00319: val_loss did not improve\n",
      "0s - loss: 10.0592 - val_loss: 9.9824\n",
      "Epoch 321/1000\n",
      "Epoch 00320: val_loss did not improve\n",
      "0s - loss: 10.0595 - val_loss: 9.9965\n",
      "Epoch 322/1000\n",
      "Epoch 00321: val_loss did not improve\n",
      "0s - loss: 10.0601 - val_loss: 9.9822\n",
      "Epoch 323/1000\n",
      "Epoch 00322: val_loss did not improve\n",
      "0s - loss: 10.0578 - val_loss: 10.0027\n",
      "Epoch 324/1000\n",
      "Epoch 00323: val_loss did not improve\n",
      "0s - loss: 10.0577 - val_loss: 10.0177\n",
      "Epoch 325/1000\n",
      "Epoch 00324: val_loss did not improve\n",
      "0s - loss: 10.0618 - val_loss: 9.9923\n",
      "Epoch 326/1000\n",
      "Epoch 00325: val_loss did not improve\n",
      "0s - loss: 10.0595 - val_loss: 10.0066\n",
      "Epoch 327/1000\n",
      "Epoch 00326: val_loss did not improve\n",
      "0s - loss: 10.0594 - val_loss: 10.0125\n",
      "Epoch 328/1000\n",
      "Epoch 00327: val_loss did not improve\n",
      "0s - loss: 10.0571 - val_loss: 9.9860\n",
      "Epoch 329/1000\n",
      "Epoch 00328: val_loss did not improve\n",
      "0s - loss: 10.0629 - val_loss: 9.9811\n",
      "Epoch 330/1000\n",
      "Epoch 00329: val_loss did not improve\n",
      "0s - loss: 10.0579 - val_loss: 9.9889\n",
      "Epoch 331/1000\n",
      "Epoch 00330: val_loss did not improve\n",
      "0s - loss: 10.0590 - val_loss: 9.9897\n",
      "Epoch 332/1000\n",
      "Epoch 00331: val_loss did not improve\n",
      "0s - loss: 10.0591 - val_loss: 9.9849\n",
      "Epoch 333/1000\n",
      "Epoch 00332: val_loss did not improve\n",
      "0s - loss: 10.0596 - val_loss: 9.9937\n",
      "Epoch 334/1000\n",
      "Epoch 00333: val_loss did not improve\n",
      "0s - loss: 10.0598 - val_loss: 10.0147\n",
      "Epoch 335/1000\n",
      "Epoch 00334: val_loss did not improve\n",
      "0s - loss: 10.0597 - val_loss: 9.9945\n",
      "Epoch 336/1000\n",
      "Epoch 00335: val_loss did not improve\n",
      "0s - loss: 10.0597 - val_loss: 10.0066\n",
      "Epoch 337/1000\n",
      "Epoch 00336: val_loss did not improve\n",
      "0s - loss: 10.0579 - val_loss: 10.0139\n",
      "Epoch 338/1000\n",
      "Epoch 00337: val_loss did not improve\n",
      "0s - loss: 10.0584 - val_loss: 9.9880\n",
      "Epoch 339/1000\n",
      "Epoch 00338: val_loss did not improve\n",
      "0s - loss: 10.0598 - val_loss: 9.9823\n",
      "Epoch 340/1000\n",
      "Epoch 00339: val_loss did not improve\n",
      "0s - loss: 10.0581 - val_loss: 10.0092\n",
      "Epoch 341/1000\n",
      "Epoch 00340: val_loss did not improve\n",
      "0s - loss: 10.0577 - val_loss: 9.9828\n",
      "Epoch 342/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00341: val_loss did not improve\n",
      "0s - loss: 10.0591 - val_loss: 10.0055\n",
      "Epoch 343/1000\n",
      "Epoch 00342: val_loss did not improve\n",
      "0s - loss: 10.0613 - val_loss: 9.9990\n",
      "Epoch 344/1000\n",
      "Epoch 00343: val_loss did not improve\n",
      "0s - loss: 10.0616 - val_loss: 10.0001\n",
      "Epoch 345/1000\n",
      "Epoch 00344: val_loss did not improve\n",
      "0s - loss: 10.0585 - val_loss: 10.0063\n",
      "Epoch 346/1000\n",
      "Epoch 00345: val_loss did not improve\n",
      "0s - loss: 10.0589 - val_loss: 9.9762\n",
      "Epoch 347/1000\n",
      "Epoch 00346: val_loss did not improve\n",
      "0s - loss: 10.0606 - val_loss: 9.9974\n",
      "Epoch 348/1000\n",
      "Epoch 00347: val_loss did not improve\n",
      "0s - loss: 10.0581 - val_loss: 9.9987\n",
      "Epoch 349/1000\n",
      "Epoch 00348: val_loss did not improve\n",
      "0s - loss: 10.0589 - val_loss: 10.0071\n",
      "Epoch 350/1000\n",
      "Epoch 00349: val_loss did not improve\n",
      "0s - loss: 10.0584 - val_loss: 10.0064\n",
      "Epoch 351/1000\n",
      "Epoch 00350: val_loss did not improve\n",
      "0s - loss: 10.0593 - val_loss: 9.9625\n",
      "Epoch 352/1000\n",
      "Epoch 00351: val_loss did not improve\n",
      "0s - loss: 10.0604 - val_loss: 10.0113\n",
      "Epoch 353/1000\n",
      "Epoch 00352: val_loss did not improve\n",
      "0s - loss: 10.0610 - val_loss: 9.9871\n",
      "Epoch 354/1000\n",
      "Epoch 00353: val_loss did not improve\n",
      "0s - loss: 10.0585 - val_loss: 10.0125\n",
      "Epoch 355/1000\n",
      "Epoch 00354: val_loss did not improve\n",
      "0s - loss: 10.0590 - val_loss: 10.0065\n",
      "Epoch 356/1000\n",
      "Epoch 00355: val_loss did not improve\n",
      "0s - loss: 10.0647 - val_loss: 10.0037\n",
      "Epoch 357/1000\n",
      "Epoch 00356: val_loss did not improve\n",
      "0s - loss: 10.0583 - val_loss: 9.9987\n",
      "Epoch 358/1000\n",
      "Epoch 00357: val_loss did not improve\n",
      "0s - loss: 10.0584 - val_loss: 10.0146\n",
      "Epoch 359/1000\n",
      "Epoch 00358: val_loss did not improve\n",
      "0s - loss: 10.0567 - val_loss: 9.9932\n",
      "Epoch 360/1000\n",
      "Epoch 00359: val_loss did not improve\n",
      "0s - loss: 10.0587 - val_loss: 10.0082\n",
      "Epoch 361/1000\n",
      "Epoch 00360: val_loss did not improve\n",
      "0s - loss: 10.0585 - val_loss: 10.0151\n",
      "Epoch 362/1000\n",
      "Epoch 00361: val_loss did not improve\n",
      "0s - loss: 10.0574 - val_loss: 9.9956\n",
      "Epoch 363/1000\n",
      "Epoch 00362: val_loss did not improve\n",
      "0s - loss: 10.0588 - val_loss: 9.9993\n",
      "Epoch 364/1000\n",
      "Epoch 00363: val_loss did not improve\n",
      "0s - loss: 10.0577 - val_loss: 9.9844\n",
      "Epoch 365/1000\n",
      "Epoch 00364: val_loss did not improve\n",
      "0s - loss: 10.0592 - val_loss: 9.9970\n",
      "Epoch 366/1000\n",
      "Epoch 00365: val_loss did not improve\n",
      "0s - loss: 10.0584 - val_loss: 9.9984\n",
      "Epoch 367/1000\n",
      "Epoch 00366: val_loss did not improve\n",
      "0s - loss: 10.0622 - val_loss: 10.0052\n",
      "Epoch 368/1000\n",
      "Epoch 00367: val_loss did not improve\n",
      "0s - loss: 10.0575 - val_loss: 9.9805\n",
      "Epoch 369/1000\n",
      "Epoch 00368: val_loss did not improve\n",
      "0s - loss: 10.0587 - val_loss: 9.9896\n",
      "Epoch 370/1000\n",
      "Epoch 00369: val_loss did not improve\n",
      "0s - loss: 10.0578 - val_loss: 10.0030\n",
      "Epoch 371/1000\n",
      "Epoch 00370: val_loss did not improve\n",
      "0s - loss: 10.0587 - val_loss: 9.9770\n",
      "Epoch 372/1000\n",
      "Epoch 00371: val_loss did not improve\n",
      "0s - loss: 10.0602 - val_loss: 9.9975\n",
      "Epoch 373/1000\n",
      "Epoch 00372: val_loss did not improve\n",
      "0s - loss: 10.0576 - val_loss: 10.0077\n",
      "Epoch 374/1000\n",
      "Epoch 00373: val_loss did not improve\n",
      "0s - loss: 10.0575 - val_loss: 9.9893\n",
      "Epoch 375/1000\n",
      "Epoch 00374: val_loss did not improve\n",
      "0s - loss: 10.0582 - val_loss: 9.9989\n",
      "Epoch 376/1000\n",
      "Epoch 00375: val_loss did not improve\n",
      "0s - loss: 10.0579 - val_loss: 9.9882\n",
      "Epoch 377/1000\n",
      "Epoch 00376: val_loss did not improve\n",
      "0s - loss: 10.0572 - val_loss: 10.0016\n",
      "Epoch 378/1000\n",
      "Epoch 00377: val_loss did not improve\n",
      "0s - loss: 10.0583 - val_loss: 10.0185\n",
      "Epoch 379/1000\n",
      "Epoch 00378: val_loss did not improve\n",
      "0s - loss: 10.0572 - val_loss: 10.0075\n",
      "Epoch 380/1000\n",
      "Epoch 00379: val_loss did not improve\n",
      "0s - loss: 10.0597 - val_loss: 10.0162\n",
      "Epoch 381/1000\n",
      "Epoch 00380: val_loss did not improve\n",
      "0s - loss: 10.0604 - val_loss: 10.0044\n",
      "Epoch 382/1000\n",
      "Epoch 00381: val_loss did not improve\n",
      "0s - loss: 10.0628 - val_loss: 9.9985\n",
      "Epoch 383/1000\n",
      "Epoch 00382: val_loss did not improve\n",
      "0s - loss: 10.0581 - val_loss: 10.0011\n",
      "Epoch 384/1000\n",
      "Epoch 00383: val_loss did not improve\n",
      "0s - loss: 10.0608 - val_loss: 9.9960\n",
      "Epoch 385/1000\n",
      "Epoch 00384: val_loss did not improve\n",
      "0s - loss: 10.0564 - val_loss: 10.0232\n",
      "Epoch 386/1000\n",
      "Epoch 00385: val_loss did not improve\n",
      "0s - loss: 10.0598 - val_loss: 9.9949\n",
      "Epoch 387/1000\n",
      "Epoch 00386: val_loss did not improve\n",
      "0s - loss: 10.0574 - val_loss: 10.0162\n",
      "Epoch 388/1000\n",
      "Epoch 00387: val_loss did not improve\n",
      "0s - loss: 10.0569 - val_loss: 9.9878\n",
      "Epoch 389/1000\n",
      "Epoch 00388: val_loss did not improve\n",
      "0s - loss: 10.0589 - val_loss: 9.9771\n",
      "Epoch 390/1000\n",
      "Epoch 00389: val_loss did not improve\n",
      "0s - loss: 10.0578 - val_loss: 9.9985\n",
      "Epoch 391/1000\n",
      "Epoch 00390: val_loss did not improve\n",
      "0s - loss: 10.0626 - val_loss: 10.0007\n",
      "Epoch 392/1000\n",
      "Epoch 00391: val_loss did not improve\n",
      "0s - loss: 10.0584 - val_loss: 10.0019\n",
      "Epoch 393/1000\n",
      "Epoch 00392: val_loss did not improve\n",
      "0s - loss: 10.0584 - val_loss: 10.0193\n",
      "Epoch 394/1000\n",
      "Epoch 00393: val_loss did not improve\n",
      "0s - loss: 10.0573 - val_loss: 9.9896\n",
      "Epoch 395/1000\n",
      "Epoch 00394: val_loss did not improve\n",
      "0s - loss: 10.0565 - val_loss: 10.0019\n",
      "Epoch 396/1000\n",
      "Epoch 00395: val_loss did not improve\n",
      "0s - loss: 10.0583 - val_loss: 9.9909\n",
      "Epoch 397/1000\n",
      "Epoch 00396: val_loss did not improve\n",
      "0s - loss: 10.0596 - val_loss: 9.9706\n",
      "Epoch 398/1000\n",
      "Epoch 00397: val_loss did not improve\n",
      "0s - loss: 10.0580 - val_loss: 9.9962\n",
      "Epoch 399/1000\n",
      "Epoch 00398: val_loss did not improve\n",
      "0s - loss: 10.0580 - val_loss: 10.0202\n",
      "Epoch 400/1000\n",
      "Epoch 00399: val_loss did not improve\n",
      "0s - loss: 10.0570 - val_loss: 9.9971\n",
      "Epoch 401/1000\n",
      "Epoch 00400: val_loss did not improve\n",
      "0s - loss: 10.0553 - val_loss: 10.0124\n",
      "Epoch 402/1000\n",
      "Epoch 00401: val_loss did not improve\n",
      "0s - loss: 10.0589 - val_loss: 10.0064\n",
      "Epoch 403/1000\n",
      "Epoch 00402: val_loss did not improve\n",
      "0s - loss: 10.0561 - val_loss: 10.0109\n",
      "Epoch 404/1000\n",
      "Epoch 00403: val_loss did not improve\n",
      "0s - loss: 10.0571 - val_loss: 10.0016\n",
      "Epoch 405/1000\n",
      "Epoch 00404: val_loss did not improve\n",
      "0s - loss: 10.0555 - val_loss: 9.9916\n",
      "Epoch 406/1000\n",
      "Epoch 00405: val_loss did not improve\n",
      "0s - loss: 10.0557 - val_loss: 9.9879\n",
      "Epoch 407/1000\n",
      "Epoch 00406: val_loss did not improve\n",
      "0s - loss: 10.0553 - val_loss: 10.0061\n",
      "Epoch 408/1000\n",
      "Epoch 00407: val_loss did not improve\n",
      "0s - loss: 10.0556 - val_loss: 9.9996\n",
      "Epoch 409/1000\n",
      "Epoch 00408: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 10.0085\n",
      "Epoch 410/1000\n",
      "Epoch 00409: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 10.0049\n",
      "Epoch 411/1000\n",
      "Epoch 00410: val_loss did not improve\n",
      "0s - loss: 10.0562 - val_loss: 9.9989\n",
      "Epoch 412/1000\n",
      "Epoch 00411: val_loss did not improve\n",
      "0s - loss: 10.0567 - val_loss: 10.0190\n",
      "Epoch 413/1000\n",
      "Epoch 00412: val_loss did not improve\n",
      "0s - loss: 10.0572 - val_loss: 10.0201\n",
      "Epoch 414/1000\n",
      "Epoch 00413: val_loss did not improve\n",
      "0s - loss: 10.0566 - val_loss: 10.0015\n",
      "Epoch 415/1000\n",
      "Epoch 00414: val_loss did not improve\n",
      "0s - loss: 10.0572 - val_loss: 10.0160\n",
      "Epoch 416/1000\n",
      "Epoch 00415: val_loss did not improve\n",
      "0s - loss: 10.0572 - val_loss: 9.9949\n",
      "Epoch 417/1000\n",
      "Epoch 00416: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 9.9961\n",
      "Epoch 418/1000\n",
      "Epoch 00417: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 9.9888\n",
      "Epoch 419/1000\n",
      "Epoch 00418: val_loss did not improve\n",
      "0s - loss: 10.0557 - val_loss: 10.0116\n",
      "Epoch 420/1000\n",
      "Epoch 00419: val_loss did not improve\n",
      "0s - loss: 10.0554 - val_loss: 9.9917\n",
      "Epoch 421/1000\n",
      "Epoch 00420: val_loss did not improve\n",
      "0s - loss: 10.0568 - val_loss: 9.9919\n",
      "Epoch 422/1000\n",
      "Epoch 00421: val_loss did not improve\n",
      "0s - loss: 10.0570 - val_loss: 9.9860\n",
      "Epoch 423/1000\n",
      "Epoch 00422: val_loss did not improve\n",
      "0s - loss: 10.0568 - val_loss: 9.9842\n",
      "Epoch 424/1000\n",
      "Epoch 00423: val_loss did not improve\n",
      "0s - loss: 10.0558 - val_loss: 10.0063\n",
      "Epoch 425/1000\n",
      "Epoch 00424: val_loss did not improve\n",
      "0s - loss: 10.0568 - val_loss: 9.9813\n",
      "Epoch 426/1000\n",
      "Epoch 00425: val_loss did not improve\n",
      "0s - loss: 10.0527 - val_loss: 10.1171\n",
      "Epoch 427/1000\n",
      "Epoch 00426: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 9.9835\n",
      "Epoch 428/1000\n",
      "Epoch 00427: val_loss did not improve\n",
      "0s - loss: 10.0568 - val_loss: 10.0082\n",
      "Epoch 429/1000\n",
      "Epoch 00428: val_loss did not improve\n",
      "0s - loss: 10.0538 - val_loss: 10.0108\n",
      "Epoch 430/1000\n",
      "Epoch 00429: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 9.9887\n",
      "Epoch 431/1000\n",
      "Epoch 00430: val_loss did not improve\n",
      "0s - loss: 10.0559 - val_loss: 9.9863\n",
      "Epoch 432/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00431: val_loss did not improve\n",
      "0s - loss: 10.0557 - val_loss: 9.9917\n",
      "Epoch 433/1000\n",
      "Epoch 00432: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 9.9890\n",
      "Epoch 434/1000\n",
      "Epoch 00433: val_loss did not improve\n",
      "0s - loss: 10.0567 - val_loss: 10.0217\n",
      "Epoch 435/1000\n",
      "Epoch 00434: val_loss did not improve\n",
      "0s - loss: 10.0545 - val_loss: 9.9955\n",
      "Epoch 436/1000\n",
      "Epoch 00435: val_loss did not improve\n",
      "0s - loss: 10.0545 - val_loss: 9.9914\n",
      "Epoch 437/1000\n",
      "Epoch 00436: val_loss did not improve\n",
      "0s - loss: 10.0551 - val_loss: 9.9888\n",
      "Epoch 438/1000\n",
      "Epoch 00437: val_loss did not improve\n",
      "0s - loss: 10.0608 - val_loss: 9.9947\n",
      "Epoch 439/1000\n",
      "Epoch 00438: val_loss did not improve\n",
      "0s - loss: 10.0575 - val_loss: 10.0049\n",
      "Epoch 440/1000\n",
      "Epoch 00439: val_loss did not improve\n",
      "0s - loss: 10.0563 - val_loss: 10.0024\n",
      "Epoch 441/1000\n",
      "Epoch 00440: val_loss did not improve\n",
      "0s - loss: 10.0556 - val_loss: 9.9813\n",
      "Epoch 442/1000\n",
      "Epoch 00441: val_loss did not improve\n",
      "0s - loss: 10.0559 - val_loss: 10.0174\n",
      "Epoch 443/1000\n",
      "Epoch 00442: val_loss did not improve\n",
      "0s - loss: 10.0572 - val_loss: 10.0102\n",
      "Epoch 444/1000\n",
      "Epoch 00443: val_loss did not improve\n",
      "0s - loss: 10.0565 - val_loss: 9.9948\n",
      "Epoch 445/1000\n",
      "Epoch 00444: val_loss did not improve\n",
      "0s - loss: 10.0560 - val_loss: 9.9937\n",
      "Epoch 446/1000\n",
      "Epoch 00445: val_loss did not improve\n",
      "0s - loss: 10.0571 - val_loss: 9.9985\n",
      "Epoch 447/1000\n",
      "Epoch 00446: val_loss did not improve\n",
      "0s - loss: 10.0552 - val_loss: 10.0165\n",
      "Epoch 448/1000\n",
      "Epoch 00447: val_loss did not improve\n",
      "0s - loss: 10.0555 - val_loss: 10.0023\n",
      "Epoch 449/1000\n",
      "Epoch 00448: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 10.0010\n",
      "Epoch 450/1000\n",
      "Epoch 00449: val_loss did not improve\n",
      "0s - loss: 10.0554 - val_loss: 10.0103\n",
      "Epoch 451/1000\n",
      "Epoch 00450: val_loss did not improve\n",
      "0s - loss: 10.0551 - val_loss: 9.9835\n",
      "Epoch 452/1000\n",
      "Epoch 00451: val_loss did not improve\n",
      "0s - loss: 10.0530 - val_loss: 10.0072\n",
      "Epoch 453/1000\n",
      "Epoch 00452: val_loss did not improve\n",
      "0s - loss: 10.0546 - val_loss: 9.9875\n",
      "Epoch 454/1000\n",
      "Epoch 00453: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 9.9832\n",
      "Epoch 455/1000\n",
      "Epoch 00454: val_loss did not improve\n",
      "0s - loss: 10.0558 - val_loss: 9.9835\n",
      "Epoch 456/1000\n",
      "Epoch 00455: val_loss did not improve\n",
      "0s - loss: 10.0550 - val_loss: 9.9871\n",
      "Epoch 457/1000\n",
      "Epoch 00456: val_loss did not improve\n",
      "0s - loss: 10.0559 - val_loss: 9.9865\n",
      "Epoch 458/1000\n",
      "Epoch 00457: val_loss did not improve\n",
      "0s - loss: 10.0538 - val_loss: 10.0271\n",
      "Epoch 459/1000\n",
      "Epoch 00458: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 9.9814\n",
      "Epoch 460/1000\n",
      "Epoch 00459: val_loss did not improve\n",
      "0s - loss: 10.0525 - val_loss: 10.0232\n",
      "Epoch 461/1000\n",
      "Epoch 00460: val_loss did not improve\n",
      "0s - loss: 10.0595 - val_loss: 10.0172\n",
      "Epoch 462/1000\n",
      "Epoch 00461: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 10.0003\n",
      "Epoch 463/1000\n",
      "Epoch 00462: val_loss did not improve\n",
      "0s - loss: 10.0543 - val_loss: 10.0082\n",
      "Epoch 464/1000\n",
      "Epoch 00463: val_loss did not improve\n",
      "0s - loss: 10.0543 - val_loss: 10.0043\n",
      "Epoch 465/1000\n",
      "Epoch 00464: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 9.9936\n",
      "Epoch 466/1000\n",
      "Epoch 00465: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 10.0018\n",
      "Epoch 467/1000\n",
      "Epoch 00466: val_loss did not improve\n",
      "0s - loss: 10.0560 - val_loss: 9.9927\n",
      "Epoch 468/1000\n",
      "Epoch 00467: val_loss did not improve\n",
      "0s - loss: 10.0563 - val_loss: 9.9954\n",
      "Epoch 469/1000\n",
      "Epoch 00468: val_loss did not improve\n",
      "0s - loss: 10.0554 - val_loss: 9.9856\n",
      "Epoch 470/1000\n",
      "Epoch 00469: val_loss did not improve\n",
      "0s - loss: 10.0546 - val_loss: 9.9920\n",
      "Epoch 471/1000\n",
      "Epoch 00470: val_loss did not improve\n",
      "0s - loss: 10.0577 - val_loss: 9.9797\n",
      "Epoch 472/1000\n",
      "Epoch 00471: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 10.0638\n",
      "Epoch 473/1000\n",
      "Epoch 00472: val_loss did not improve\n",
      "0s - loss: 10.0588 - val_loss: 10.0290\n",
      "Epoch 474/1000\n",
      "Epoch 00473: val_loss did not improve\n",
      "0s - loss: 10.0554 - val_loss: 9.9950\n",
      "Epoch 475/1000\n",
      "Epoch 00474: val_loss did not improve\n",
      "0s - loss: 10.0571 - val_loss: 9.9733\n",
      "Epoch 476/1000\n",
      "Epoch 00475: val_loss did not improve\n",
      "0s - loss: 10.0544 - val_loss: 10.0237\n",
      "Epoch 477/1000\n",
      "Epoch 00476: val_loss did not improve\n",
      "0s - loss: 10.0551 - val_loss: 10.0163\n",
      "Epoch 478/1000\n",
      "Epoch 00477: val_loss did not improve\n",
      "0s - loss: 10.0540 - val_loss: 10.0135\n",
      "Epoch 479/1000\n",
      "Epoch 00478: val_loss did not improve\n",
      "0s - loss: 10.0619 - val_loss: 9.9835\n",
      "Epoch 480/1000\n",
      "Epoch 00479: val_loss did not improve\n",
      "0s - loss: 10.0609 - val_loss: 9.9839\n",
      "Epoch 481/1000\n",
      "Epoch 00480: val_loss did not improve\n",
      "0s - loss: 10.0532 - val_loss: 10.0182\n",
      "Epoch 482/1000\n",
      "Epoch 00481: val_loss did not improve\n",
      "0s - loss: 10.0541 - val_loss: 10.0012\n",
      "Epoch 483/1000\n",
      "Epoch 00482: val_loss did not improve\n",
      "0s - loss: 10.0550 - val_loss: 9.9841\n",
      "Epoch 484/1000\n",
      "Epoch 00483: val_loss did not improve\n",
      "0s - loss: 10.0575 - val_loss: 9.9897\n",
      "Epoch 485/1000\n",
      "Epoch 00484: val_loss did not improve\n",
      "0s - loss: 10.0544 - val_loss: 10.0067\n",
      "Epoch 486/1000\n",
      "Epoch 00485: val_loss did not improve\n",
      "0s - loss: 10.0540 - val_loss: 9.9642\n",
      "Epoch 487/1000\n",
      "Epoch 00486: val_loss did not improve\n",
      "0s - loss: 10.0562 - val_loss: 10.0248\n",
      "Epoch 488/1000\n",
      "Epoch 00487: val_loss did not improve\n",
      "0s - loss: 10.0556 - val_loss: 9.9788\n",
      "Epoch 489/1000\n",
      "Epoch 00488: val_loss did not improve\n",
      "0s - loss: 10.0564 - val_loss: 9.9780\n",
      "Epoch 490/1000\n",
      "Epoch 00489: val_loss did not improve\n",
      "0s - loss: 10.0569 - val_loss: 9.9964\n",
      "Epoch 491/1000\n",
      "Epoch 00490: val_loss did not improve\n",
      "0s - loss: 10.0539 - val_loss: 10.0044\n",
      "Epoch 492/1000\n",
      "Epoch 00491: val_loss did not improve\n",
      "0s - loss: 10.0569 - val_loss: 9.9762\n",
      "Epoch 493/1000\n",
      "Epoch 00492: val_loss did not improve\n",
      "0s - loss: 10.0550 - val_loss: 10.0032\n",
      "Epoch 494/1000\n",
      "Epoch 00493: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 10.0166\n",
      "Epoch 495/1000\n",
      "Epoch 00494: val_loss did not improve\n",
      "0s - loss: 10.0560 - val_loss: 10.0168\n",
      "Epoch 496/1000\n",
      "Epoch 00495: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 9.9935\n",
      "Epoch 497/1000\n",
      "Epoch 00496: val_loss did not improve\n",
      "0s - loss: 10.0564 - val_loss: 10.0029\n",
      "Epoch 498/1000\n",
      "Epoch 00497: val_loss did not improve\n",
      "0s - loss: 10.0534 - val_loss: 9.9939\n",
      "Epoch 499/1000\n",
      "Epoch 00498: val_loss did not improve\n",
      "0s - loss: 10.0566 - val_loss: 9.9855\n",
      "Epoch 500/1000\n",
      "Epoch 00499: val_loss did not improve\n",
      "0s - loss: 10.0535 - val_loss: 9.9940\n",
      "Epoch 501/1000\n",
      "Epoch 00500: val_loss did not improve\n",
      "0s - loss: 10.0593 - val_loss: 10.0129\n",
      "Epoch 502/1000\n",
      "Epoch 00501: val_loss did not improve\n",
      "0s - loss: 10.0573 - val_loss: 9.9940\n",
      "Epoch 503/1000\n",
      "Epoch 00502: val_loss did not improve\n",
      "0s - loss: 10.0559 - val_loss: 9.9882\n",
      "Epoch 504/1000\n",
      "Epoch 00503: val_loss did not improve\n",
      "0s - loss: 10.0535 - val_loss: 9.9987\n",
      "Epoch 505/1000\n",
      "Epoch 00504: val_loss did not improve\n",
      "0s - loss: 10.0554 - val_loss: 10.0037\n",
      "Epoch 506/1000\n",
      "Epoch 00505: val_loss did not improve\n",
      "0s - loss: 10.0537 - val_loss: 10.0310\n",
      "Epoch 507/1000\n",
      "Epoch 00506: val_loss did not improve\n",
      "0s - loss: 10.0572 - val_loss: 9.9807\n",
      "Epoch 508/1000\n",
      "Epoch 00507: val_loss did not improve\n",
      "0s - loss: 10.0552 - val_loss: 10.0220\n",
      "Epoch 509/1000\n",
      "Epoch 00508: val_loss did not improve\n",
      "0s - loss: 10.0561 - val_loss: 9.9885\n",
      "Epoch 510/1000\n",
      "Epoch 00509: val_loss did not improve\n",
      "0s - loss: 10.0561 - val_loss: 9.9902\n",
      "Epoch 511/1000\n",
      "Epoch 00510: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 10.0114\n",
      "Epoch 512/1000\n",
      "Epoch 00511: val_loss did not improve\n",
      "0s - loss: 10.0553 - val_loss: 9.9960\n",
      "Epoch 513/1000\n",
      "Epoch 00512: val_loss did not improve\n",
      "0s - loss: 10.0551 - val_loss: 10.0080\n",
      "Epoch 514/1000\n",
      "Epoch 00513: val_loss did not improve\n",
      "0s - loss: 10.0555 - val_loss: 10.0033\n",
      "Epoch 515/1000\n",
      "Epoch 00514: val_loss did not improve\n",
      "0s - loss: 10.0576 - val_loss: 10.0191\n",
      "Epoch 516/1000\n",
      "Epoch 00515: val_loss did not improve\n",
      "0s - loss: 10.0546 - val_loss: 10.0182\n",
      "Epoch 517/1000\n",
      "Epoch 00516: val_loss did not improve\n",
      "0s - loss: 10.0567 - val_loss: 9.9923\n",
      "Epoch 518/1000\n",
      "Epoch 00517: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 9.9997\n",
      "Epoch 519/1000\n",
      "Epoch 00518: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 9.9941\n",
      "Epoch 520/1000\n",
      "Epoch 00519: val_loss did not improve\n",
      "0s - loss: 10.0558 - val_loss: 10.0172\n",
      "Epoch 521/1000\n",
      "Epoch 00520: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 9.9985\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00521: val_loss did not improve\n",
      "0s - loss: 10.0561 - val_loss: 9.9805\n",
      "Epoch 523/1000\n",
      "Epoch 00522: val_loss did not improve\n",
      "0s - loss: 10.0535 - val_loss: 9.9979\n",
      "Epoch 524/1000\n",
      "Epoch 00523: val_loss did not improve\n",
      "0s - loss: 10.0578 - val_loss: 9.9891\n",
      "Epoch 525/1000\n",
      "Epoch 00524: val_loss did not improve\n",
      "0s - loss: 10.0570 - val_loss: 9.9853\n",
      "Epoch 526/1000\n",
      "Epoch 00525: val_loss did not improve\n",
      "0s - loss: 10.0541 - val_loss: 10.0084\n",
      "Epoch 527/1000\n",
      "Epoch 00526: val_loss did not improve\n",
      "0s - loss: 10.0559 - val_loss: 9.9937\n",
      "Epoch 528/1000\n",
      "Epoch 00527: val_loss did not improve\n",
      "0s - loss: 10.0530 - val_loss: 9.9882\n",
      "Epoch 529/1000\n",
      "Epoch 00528: val_loss did not improve\n",
      "0s - loss: 10.0572 - val_loss: 10.0123\n",
      "Epoch 530/1000\n",
      "Epoch 00529: val_loss did not improve\n",
      "0s - loss: 10.0572 - val_loss: 10.0368\n",
      "Epoch 531/1000\n",
      "Epoch 00530: val_loss did not improve\n",
      "0s - loss: 10.0538 - val_loss: 10.0050\n",
      "Epoch 532/1000\n",
      "Epoch 00531: val_loss did not improve\n",
      "0s - loss: 10.0563 - val_loss: 10.0301\n",
      "Epoch 533/1000\n",
      "Epoch 00532: val_loss did not improve\n",
      "0s - loss: 10.0592 - val_loss: 10.0231\n",
      "Epoch 534/1000\n",
      "Epoch 00533: val_loss did not improve\n",
      "0s - loss: 10.0550 - val_loss: 10.0190\n",
      "Epoch 535/1000\n",
      "Epoch 00534: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 9.9903\n",
      "Epoch 536/1000\n",
      "Epoch 00535: val_loss did not improve\n",
      "0s - loss: 10.0563 - val_loss: 9.9885\n",
      "Epoch 537/1000\n",
      "Epoch 00536: val_loss did not improve\n",
      "0s - loss: 10.0568 - val_loss: 9.9816\n",
      "Epoch 538/1000\n",
      "Epoch 00537: val_loss did not improve\n",
      "0s - loss: 10.0564 - val_loss: 9.9999\n",
      "Epoch 539/1000\n",
      "Epoch 00538: val_loss did not improve\n",
      "0s - loss: 10.0562 - val_loss: 9.9596\n",
      "Epoch 540/1000\n",
      "Epoch 00539: val_loss did not improve\n",
      "0s - loss: 10.0555 - val_loss: 9.9987\n",
      "Epoch 541/1000\n",
      "Epoch 00540: val_loss did not improve\n",
      "0s - loss: 10.0550 - val_loss: 10.0049\n",
      "Epoch 542/1000\n",
      "Epoch 00541: val_loss did not improve\n",
      "0s - loss: 10.0555 - val_loss: 9.9990\n",
      "Epoch 543/1000\n",
      "Epoch 00542: val_loss did not improve\n",
      "0s - loss: 10.0625 - val_loss: 10.0068\n",
      "Epoch 544/1000\n",
      "Epoch 00543: val_loss did not improve\n",
      "0s - loss: 10.0590 - val_loss: 10.0094\n",
      "Epoch 545/1000\n",
      "Epoch 00544: val_loss did not improve\n",
      "0s - loss: 10.0560 - val_loss: 10.0202\n",
      "Epoch 546/1000\n",
      "Epoch 00545: val_loss did not improve\n",
      "0s - loss: 10.0540 - val_loss: 10.0026\n",
      "Epoch 547/1000\n",
      "Epoch 00546: val_loss did not improve\n",
      "0s - loss: 10.0528 - val_loss: 9.9935\n",
      "Epoch 548/1000\n",
      "Epoch 00547: val_loss did not improve\n",
      "0s - loss: 10.0540 - val_loss: 9.9881\n",
      "Epoch 549/1000\n",
      "Epoch 00548: val_loss did not improve\n",
      "0s - loss: 10.0541 - val_loss: 9.9922\n",
      "Epoch 550/1000\n",
      "Epoch 00549: val_loss did not improve\n",
      "0s - loss: 10.0544 - val_loss: 10.0051\n",
      "Epoch 551/1000\n",
      "Epoch 00550: val_loss did not improve\n",
      "0s - loss: 10.0538 - val_loss: 10.0130\n",
      "Epoch 552/1000\n",
      "Epoch 00551: val_loss did not improve\n",
      "0s - loss: 10.0527 - val_loss: 10.0081\n",
      "Epoch 553/1000\n",
      "Epoch 00552: val_loss did not improve\n",
      "0s - loss: 10.0556 - val_loss: 10.0028\n",
      "Epoch 554/1000\n",
      "Epoch 00553: val_loss did not improve\n",
      "0s - loss: 10.0540 - val_loss: 10.0150\n",
      "Epoch 555/1000\n",
      "Epoch 00554: val_loss did not improve\n",
      "0s - loss: 10.0536 - val_loss: 9.9915\n",
      "Epoch 556/1000\n",
      "Epoch 00555: val_loss did not improve\n",
      "0s - loss: 10.0578 - val_loss: 9.9899\n",
      "Epoch 557/1000\n",
      "Epoch 00556: val_loss did not improve\n",
      "0s - loss: 10.0532 - val_loss: 10.0220\n",
      "Epoch 558/1000\n",
      "Epoch 00557: val_loss did not improve\n",
      "0s - loss: 10.0543 - val_loss: 10.0015\n",
      "Epoch 559/1000\n",
      "Epoch 00558: val_loss did not improve\n",
      "0s - loss: 10.0546 - val_loss: 9.9875\n",
      "Epoch 560/1000\n",
      "Epoch 00559: val_loss did not improve\n",
      "0s - loss: 10.0541 - val_loss: 10.0007\n",
      "Epoch 561/1000\n",
      "Epoch 00560: val_loss did not improve\n",
      "0s - loss: 10.0541 - val_loss: 9.9963\n",
      "Epoch 562/1000\n",
      "Epoch 00561: val_loss did not improve\n",
      "0s - loss: 10.0533 - val_loss: 10.0093\n",
      "Epoch 563/1000\n",
      "Epoch 00562: val_loss did not improve\n",
      "0s - loss: 10.0559 - val_loss: 9.9773\n",
      "Epoch 564/1000\n",
      "Epoch 00563: val_loss did not improve\n",
      "0s - loss: 10.0539 - val_loss: 9.9881\n",
      "Epoch 565/1000\n",
      "Epoch 00564: val_loss did not improve\n",
      "0s - loss: 10.0535 - val_loss: 9.9894\n",
      "Epoch 566/1000\n",
      "Epoch 00565: val_loss did not improve\n",
      "0s - loss: 10.0536 - val_loss: 10.0045\n",
      "Epoch 567/1000\n",
      "Epoch 00566: val_loss did not improve\n",
      "0s - loss: 10.0558 - val_loss: 10.0031\n",
      "Epoch 568/1000\n",
      "Epoch 00567: val_loss did not improve\n",
      "0s - loss: 10.0550 - val_loss: 9.9755\n",
      "Epoch 569/1000\n",
      "Epoch 00568: val_loss did not improve\n",
      "0s - loss: 10.0538 - val_loss: 9.9906\n",
      "Epoch 570/1000\n",
      "Epoch 00569: val_loss did not improve\n",
      "0s - loss: 10.0540 - val_loss: 10.0009\n",
      "Epoch 571/1000\n",
      "Epoch 00570: val_loss did not improve\n",
      "0s - loss: 10.0553 - val_loss: 10.0026\n",
      "Epoch 572/1000\n",
      "Epoch 00571: val_loss did not improve\n",
      "0s - loss: 10.0545 - val_loss: 9.9962\n",
      "Epoch 573/1000\n",
      "Epoch 00572: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 10.0209\n",
      "Epoch 574/1000\n",
      "Epoch 00573: val_loss did not improve\n",
      "0s - loss: 10.0551 - val_loss: 9.9868\n",
      "Epoch 575/1000\n",
      "Epoch 00574: val_loss did not improve\n",
      "0s - loss: 10.0541 - val_loss: 10.0041\n",
      "Epoch 576/1000\n",
      "Epoch 00575: val_loss did not improve\n",
      "0s - loss: 10.0546 - val_loss: 9.9782\n",
      "Epoch 577/1000\n",
      "Epoch 00576: val_loss did not improve\n",
      "0s - loss: 10.0531 - val_loss: 10.0026\n",
      "Epoch 578/1000\n",
      "Epoch 00577: val_loss did not improve\n",
      "0s - loss: 10.0544 - val_loss: 9.9882\n",
      "Epoch 579/1000\n",
      "Epoch 00578: val_loss did not improve\n",
      "0s - loss: 10.0532 - val_loss: 9.9973\n",
      "Epoch 580/1000\n",
      "Epoch 00579: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 10.0057\n",
      "Epoch 581/1000\n",
      "Epoch 00580: val_loss did not improve\n",
      "0s - loss: 10.0526 - val_loss: 10.0081\n",
      "Epoch 582/1000\n",
      "Epoch 00581: val_loss did not improve\n",
      "0s - loss: 10.0530 - val_loss: 10.0148\n",
      "Epoch 583/1000\n",
      "Epoch 00582: val_loss did not improve\n",
      "1s - loss: 10.0527 - val_loss: 10.0026\n",
      "Epoch 584/1000\n",
      "Epoch 00583: val_loss did not improve\n",
      "0s - loss: 10.0535 - val_loss: 9.9906\n",
      "Epoch 585/1000\n",
      "Epoch 00584: val_loss did not improve\n",
      "0s - loss: 10.0527 - val_loss: 10.0200\n",
      "Epoch 586/1000\n",
      "Epoch 00585: val_loss did not improve\n",
      "0s - loss: 10.0557 - val_loss: 10.0205\n",
      "Epoch 587/1000\n",
      "Epoch 00586: val_loss did not improve\n",
      "0s - loss: 10.0543 - val_loss: 10.0270\n",
      "Epoch 588/1000\n",
      "Epoch 00587: val_loss did not improve\n",
      "0s - loss: 10.0548 - val_loss: 9.9995\n",
      "Epoch 589/1000\n",
      "Epoch 00588: val_loss did not improve\n",
      "0s - loss: 10.0556 - val_loss: 10.0081\n",
      "Epoch 590/1000\n",
      "Epoch 00589: val_loss did not improve\n",
      "0s - loss: 10.0531 - val_loss: 10.0009\n",
      "Epoch 591/1000\n",
      "Epoch 00590: val_loss did not improve\n",
      "0s - loss: 10.0553 - val_loss: 10.0016\n",
      "Epoch 592/1000\n",
      "Epoch 00591: val_loss did not improve\n",
      "0s - loss: 10.0534 - val_loss: 10.0123\n",
      "Epoch 593/1000\n",
      "Epoch 00592: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 10.0033\n",
      "Epoch 594/1000\n",
      "Epoch 00593: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 9.9877\n",
      "Epoch 595/1000\n",
      "Epoch 00594: val_loss did not improve\n",
      "0s - loss: 10.0546 - val_loss: 9.9936\n",
      "Epoch 596/1000\n",
      "Epoch 00595: val_loss did not improve\n",
      "0s - loss: 10.0576 - val_loss: 10.0146\n",
      "Epoch 597/1000\n",
      "Epoch 00596: val_loss did not improve\n",
      "0s - loss: 10.0580 - val_loss: 10.0149\n",
      "Epoch 598/1000\n",
      "Epoch 00597: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 10.0082\n",
      "Epoch 599/1000\n",
      "Epoch 00598: val_loss did not improve\n",
      "0s - loss: 10.0539 - val_loss: 9.9957\n",
      "Epoch 600/1000\n",
      "Epoch 00599: val_loss did not improve\n",
      "0s - loss: 10.0557 - val_loss: 10.0078\n",
      "Epoch 601/1000\n",
      "Epoch 00600: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 9.9922\n",
      "Epoch 602/1000\n",
      "Epoch 00601: val_loss did not improve\n",
      "0s - loss: 10.0574 - val_loss: 9.9618\n",
      "Epoch 603/1000\n",
      "Epoch 00602: val_loss did not improve\n",
      "0s - loss: 10.0537 - val_loss: 10.0142\n",
      "Epoch 604/1000\n",
      "Epoch 00603: val_loss did not improve\n",
      "0s - loss: 10.0565 - val_loss: 9.9947\n",
      "Epoch 605/1000\n",
      "Epoch 00604: val_loss did not improve\n",
      "0s - loss: 10.0534 - val_loss: 10.0231\n",
      "Epoch 606/1000\n",
      "Epoch 00605: val_loss did not improve\n",
      "0s - loss: 10.0543 - val_loss: 10.0050\n",
      "Epoch 607/1000\n",
      "Epoch 00606: val_loss did not improve\n",
      "0s - loss: 10.0543 - val_loss: 9.9843\n",
      "Epoch 608/1000\n",
      "Epoch 00607: val_loss did not improve\n",
      "0s - loss: 10.0538 - val_loss: 10.0249\n",
      "Epoch 609/1000\n",
      "Epoch 00608: val_loss did not improve\n",
      "0s - loss: 10.0560 - val_loss: 10.0106\n",
      "Epoch 610/1000\n",
      "Epoch 00609: val_loss did not improve\n",
      "0s - loss: 10.0539 - val_loss: 10.0118\n",
      "Epoch 611/1000\n",
      "Epoch 00610: val_loss did not improve\n",
      "0s - loss: 10.0588 - val_loss: 10.0293\n",
      "Epoch 612/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00611: val_loss did not improve\n",
      "0s - loss: 10.0546 - val_loss: 10.0198\n",
      "Epoch 613/1000\n",
      "Epoch 00612: val_loss did not improve\n",
      "0s - loss: 10.0530 - val_loss: 10.0038\n",
      "Epoch 614/1000\n",
      "Epoch 00613: val_loss did not improve\n",
      "0s - loss: 10.0541 - val_loss: 10.0107\n",
      "Epoch 615/1000\n",
      "Epoch 00614: val_loss did not improve\n",
      "0s - loss: 10.0567 - val_loss: 9.9884\n",
      "Epoch 616/1000\n",
      "Epoch 00615: val_loss did not improve\n",
      "0s - loss: 10.0558 - val_loss: 10.0007\n",
      "Epoch 617/1000\n",
      "Epoch 00616: val_loss did not improve\n",
      "0s - loss: 10.0562 - val_loss: 9.9753\n",
      "Epoch 618/1000\n",
      "Epoch 00617: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 9.9997\n",
      "Epoch 619/1000\n",
      "Epoch 00618: val_loss did not improve\n",
      "0s - loss: 10.0560 - val_loss: 10.0126\n",
      "Epoch 620/1000\n",
      "Epoch 00619: val_loss did not improve\n",
      "0s - loss: 10.0546 - val_loss: 10.0109\n",
      "Epoch 621/1000\n",
      "Epoch 00620: val_loss did not improve\n",
      "0s - loss: 10.0538 - val_loss: 10.0300\n",
      "Epoch 622/1000\n",
      "Epoch 00621: val_loss did not improve\n",
      "0s - loss: 10.0548 - val_loss: 9.9780\n",
      "Epoch 623/1000\n",
      "Epoch 00622: val_loss did not improve\n",
      "0s - loss: 10.0540 - val_loss: 10.0064\n",
      "Epoch 624/1000\n",
      "Epoch 00623: val_loss did not improve\n",
      "0s - loss: 10.0578 - val_loss: 10.0038\n",
      "Epoch 625/1000\n",
      "Epoch 00624: val_loss did not improve\n",
      "0s - loss: 10.0547 - val_loss: 10.0037\n",
      "Epoch 626/1000\n",
      "Epoch 00625: val_loss did not improve\n",
      "0s - loss: 10.0527 - val_loss: 10.0176\n",
      "Epoch 627/1000\n",
      "Epoch 00626: val_loss did not improve\n",
      "0s - loss: 10.0549 - val_loss: 9.9865\n",
      "Epoch 628/1000\n",
      "Epoch 00627: val_loss did not improve\n",
      "0s - loss: 10.0560 - val_loss: 10.0196\n",
      "Epoch 629/1000\n",
      "Epoch 00628: val_loss did not improve\n",
      "0s - loss: 10.0532 - val_loss: 9.9940\n",
      "Epoch 630/1000\n",
      "Epoch 00629: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 9.9878\n",
      "Epoch 631/1000\n",
      "Epoch 00630: val_loss did not improve\n",
      "0s - loss: 10.0564 - val_loss: 9.9895\n",
      "Epoch 632/1000\n",
      "Epoch 00631: val_loss did not improve\n",
      "0s - loss: 10.0524 - val_loss: 10.0086\n",
      "Epoch 633/1000\n",
      "Epoch 00632: val_loss did not improve\n",
      "0s - loss: 10.0525 - val_loss: 9.9990\n",
      "Epoch 634/1000\n",
      "Epoch 00633: val_loss did not improve\n",
      "0s - loss: 10.0541 - val_loss: 10.0021\n",
      "Epoch 635/1000\n",
      "Epoch 00634: val_loss did not improve\n",
      "1s - loss: 10.0536 - val_loss: 9.9910\n",
      "Epoch 636/1000\n",
      "Epoch 00635: val_loss did not improve\n",
      "0s - loss: 10.0555 - val_loss: 10.0079\n",
      "Epoch 637/1000\n",
      "Epoch 00636: val_loss did not improve\n",
      "0s - loss: 10.0561 - val_loss: 9.9933\n",
      "Epoch 638/1000\n",
      "Epoch 00637: val_loss did not improve\n",
      "0s - loss: 10.0541 - val_loss: 9.9829\n",
      "Epoch 639/1000\n",
      "Epoch 00638: val_loss did not improve\n",
      "0s - loss: 10.0577 - val_loss: 9.9946\n",
      "Epoch 640/1000\n",
      "Epoch 00639: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 10.0010\n",
      "Epoch 641/1000\n",
      "Epoch 00640: val_loss did not improve\n",
      "0s - loss: 10.0558 - val_loss: 9.9820\n",
      "Epoch 642/1000\n",
      "Epoch 00641: val_loss did not improve\n",
      "0s - loss: 10.0536 - val_loss: 9.9921\n",
      "Epoch 643/1000\n",
      "Epoch 00642: val_loss did not improve\n",
      "0s - loss: 10.0546 - val_loss: 10.0041\n",
      "Epoch 644/1000\n",
      "Epoch 00643: val_loss did not improve\n",
      "0s - loss: 10.0548 - val_loss: 10.0238\n",
      "Epoch 645/1000\n",
      "Epoch 00644: val_loss did not improve\n",
      "0s - loss: 10.0550 - val_loss: 10.0070\n",
      "Epoch 646/1000\n",
      "Epoch 00645: val_loss did not improve\n",
      "0s - loss: 10.0555 - val_loss: 9.9927\n",
      "Epoch 647/1000\n",
      "Epoch 00646: val_loss did not improve\n",
      "0s - loss: 10.0563 - val_loss: 9.9968\n",
      "Epoch 648/1000\n",
      "Epoch 00647: val_loss did not improve\n",
      "0s - loss: 10.0550 - val_loss: 10.0016\n",
      "Epoch 649/1000\n",
      "Epoch 00648: val_loss did not improve\n",
      "0s - loss: 10.0550 - val_loss: 9.9979\n",
      "Epoch 650/1000\n",
      "Epoch 00649: val_loss did not improve\n",
      "0s - loss: 10.0544 - val_loss: 9.9809\n",
      "Epoch 651/1000\n",
      "Epoch 00650: val_loss did not improve\n",
      "0s - loss: 10.0553 - val_loss: 10.0026\n",
      "Epoch 652/1000\n",
      "Epoch 00651: val_loss did not improve\n",
      "0s - loss: 10.0555 - val_loss: 9.9924\n",
      "Epoch 653/1000\n",
      "Epoch 00652: val_loss did not improve\n",
      "0s - loss: 10.0539 - val_loss: 10.0021\n",
      "Epoch 654/1000\n",
      "Epoch 00653: val_loss did not improve\n",
      "0s - loss: 10.0534 - val_loss: 10.0019\n",
      "Epoch 655/1000\n",
      "Epoch 00654: val_loss did not improve\n",
      "0s - loss: 10.0552 - val_loss: 9.9729\n",
      "Epoch 656/1000\n",
      "Epoch 00655: val_loss did not improve\n",
      "0s - loss: 10.0537 - val_loss: 10.0010\n",
      "Epoch 657/1000\n",
      "Epoch 00656: val_loss did not improve\n",
      "0s - loss: 10.0536 - val_loss: 10.0293\n",
      "Epoch 658/1000\n",
      "Epoch 00657: val_loss did not improve\n",
      "0s - loss: 10.0542 - val_loss: 9.9797\n",
      "Epoch 659/1000\n",
      "Epoch 00658: val_loss did not improve\n",
      "0s - loss: 10.0571 - val_loss: 9.9974\n",
      "Epoch 660/1000\n",
      "Epoch 00659: val_loss did not improve\n",
      "0s - loss: 10.0541 - val_loss: 10.0172\n",
      "Epoch 661/1000\n",
      "Epoch 00660: val_loss did not improve\n",
      "0s - loss: 10.0551 - val_loss: 10.0154\n",
      "Epoch 662/1000\n",
      "Epoch 00661: val_loss did not improve\n",
      "0s - loss: 10.0527 - val_loss: 9.9912\n",
      "Epoch 663/1000\n",
      "Epoch 00662: val_loss did not improve\n",
      "0s - loss: 10.0536 - val_loss: 9.9833\n",
      "Epoch 664/1000\n",
      "Epoch 00663: val_loss did not improve\n",
      "0s - loss: 10.0548 - val_loss: 9.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x21e2b12d0b8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trene modellen\n",
    "np.random.seed(7)\n",
    "dnn_keras_model.fit(x_train_matrix,y_train_matrix, epochs = 1000, batch_size=32, verbose=2, \n",
    "                       validation_split=0.2,\n",
    "                       callbacks=[checkpoint,early_stopping])\n",
    "\n",
    "\n",
    "# validation_split=0.20\n",
    "#validation_data=(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finished_model = dnn_keras_model\n",
    "\n",
    "finished_model = models.load_model('checkpoint_model_LSTM_advanced.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediksjon på testsett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = finished_model.predict(x_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: \t\t\t 12.3592\n",
      "Mean Squared Error: \t\t\t 230.741\n",
      "Root Mean Squared Error: \t\t 15.1902\n"
     ]
    }
   ],
   "source": [
    "# 5000 epocs , b_size = 10, 24(24)[10](1)\n",
    "print('Mean Absolute Error: \\t\\t\\t', metrics.mean_absolute_error(y_test_matrix, final_preds))\n",
    "print('Mean Squared Error: \\t\\t\\t', metrics.mean_squared_error(y_test_matrix, final_preds))\n",
    "print('Root Mean Squared Error: \\t\\t', np.sqrt(metrics.mean_squared_error(y_test_matrix, final_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediksjon på treningdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = finished_model.predict(x_train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: \t\t\t 10.0439\n",
      "Mean Squared Error: \t\t\t 161.323\n",
      "Root Mean Squared Error: \t\t 12.7013\n"
     ]
    }
   ],
   "source": [
    "# 70% av data (benyttet til treningen)\n",
    "print('Mean Absolute Error: \\t\\t\\t', metrics.mean_absolute_error(y_train_matrix,train_preds))\n",
    "print('Mean Squared Error: \\t\\t\\t', metrics.mean_squared_error(y_train_matrix, train_preds))\n",
    "print('Root Mean Squared Error: \\t\\t', np.sqrt(metrics.mean_squared_error(y_train_matrix, train_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualisere resultater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Lager oversikt over testdataen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = list(final_preds)\n",
    "\n",
    "predictions_list = []\n",
    "\n",
    "for pred in predictions:\n",
    "    predictions_list.append(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Oversikt = pd.DataFrame(data = {'real': y_test_matrix, 'predicitions': predictions_list})\n",
    "\n",
    "Oversikt['differanse'] = Oversikt['real'] - Oversikt['predicitions'] \n",
    "\n",
    "Oversikt['abs_diff'] = Oversikt['differanse'].apply(abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot med fargekodede prediskjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACEIAAARjCAYAAABhKBMtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQAAAAAAAACAbihCAAAAAAAAAADd+H+VR93GJTB3iwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21e2b2c6f28>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 561,
       "width": 1057
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = Oversikt.plot.scatter(x='real',y='predicitions',\n",
    "                   c='abs_diff',cmap='coolwarm', figsize = (20,10))\n",
    "\n",
    "ax.set_xlabel(\"x label\")\n",
    "\n",
    "#remove spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "#fig.savefig('keras_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feilfordelingen av prediksjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACRoAAAS3CAYAAACDylRoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYvUkkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21e2feb3b70>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 603,
       "width": 1165
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = Oversikt['differanse'].hist(bins=60,figsize = (20,10))\n",
    "\n",
    "plt.xlabel('Verdi av feilprediskjon')\n",
    "plt.ylabel('Antall timer')\n",
    "plt.title('Fordeling av feilprediskjoner')\n",
    "\n",
    "#remove spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "#fig.savefig('hist av abs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ekte plott av prediksjonene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forsøk på å hente ut et utdrag av dataen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected lstm_1_input to have 3 dimensions, but got array with shape (4895, 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-b640972e3291>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinished_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredictions_all_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 900\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1512\u001b[1;33m         check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1513\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1514\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programmer\\Python\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;34m'Error when checking '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             ' dimensions, but got array with shape ' + str(array.shape))\n\u001b[0m\u001b[0;32m    134\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected lstm_1_input to have 3 dimensions, but got array with shape (4895, 65)"
     ]
    }
   ],
   "source": [
    "all_predictions = finished_model.predict(x[:,:])\n",
    "\n",
    "predictions_all = list(all_predictions)\n",
    "\n",
    "predictions_all_list = []\n",
    "\n",
    "for pred in predictions_all:\n",
    "    predictions_all_list.append(pred[0])\n",
    "    \n",
    "timeline = pd.DataFrame(data = {'real': y[:], 'predicitions': predictions_all_list})\n",
    "\n",
    "# Adjust in order to plot 'dagens modell'\n",
    "data_raw.dropna(inplace=True)\n",
    "data_raw.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidsplot av data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Justere tidslinjen på plottet\n",
    "start = 0\n",
    "slutt = 20\n",
    "\n",
    "ax = timeline.loc[start:slutt,'real'].plot(figsize=(20,8))\n",
    "ax = timeline.loc[start:slutt,'predicitions'].plot(figsize=(20,8))\n",
    "ax = data_raw.loc[start:slutt,'YVIK-YtreVikna1-Sum-produksjon'].plot(figsize=(20,8))\n",
    "\n",
    " \n",
    "plt.xlabel('Tid (antall timer)')\n",
    "plt.ylabel('Produksjon i Mega Watt (MW)')\n",
    "plt.title('Utdrag fra tidsperioden')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "\n",
    "#remove spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Saves figure\n",
    "fig = ax.get_figure()\n",
    "#fig.savefig('september10.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
